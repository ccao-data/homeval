---
title: "Cook County Assessor’s Model Value Report (Experimental)"
title-block-banner: "#294298"
subtitle: "<b>PIN: `r glue::glue('<a style=color:white;text-decoration:underline target=_blank href=https://www.cookcountyassessor.com/pin/{params$pin}>{ccao::pin_format_pretty(params$pin)}</a>')`</b>"
execute:
  echo: false
  warning: false
format:
  html:
    embed-resources: true
    fig-align: center
    fontsize: 12pt
    grid:
      # Add a little more width to the body so the char table is full width
      body-width: 1000px
knitr:
  opts_chunk:
    out.width: "100%"
editor: source
params:
  run_id: "2025-02-11-charming-eric"
  year: "2025"
  # Good PINs for testing:
  #   * Single card: 14051280390000
  #   * Multicard: 16251020210000
  #   * Past sale is a comp: 14331000240000
  pin: "08102100010000"
  num_comps: 5
---


```{r}
# This block loads data for the selected parcel, year, and model run.
# Start by loading R dependencies
library(arrow)
library(ccao)
library(dplyr)
library(noctua)
library(stringr)
library(tibble)
library(tidyr)
library(tools)


# Helper function to wrap a PIN in a link for display purposes
link_pin <- function(pin, display_text) {
  text <- ifelse(!missing(display_text), display_text, ccao::pin_format_pretty(pin))
  return(
    glue::glue(
      "<a target=_blank href=https://www.cookcountyassessor.com/pin/{pin}>{text}</a>"
    )
  )
}

# Check if this PIN/year combo is cached, and skip data loading if so
base_cache_file_path <- glue::glue("cache/{params$run_id}_{params$pin}_{params$year}")
cache_files <- list(
  assessment = glue::glue("{base_cache_file_path}_asmt.parquet"),
  comp = glue::glue("{base_cache_file_path}_comp.parquet"),
  metadata = glue::glue("{base_cache_file_path}_meta.parquet")
)

if (cache_files %>% sapply(file.exists) %>% all()) {
  assessment_df <- read_parquet(cache_files$assessment)
  comp_df <- read_parquet(cache_files$comp)
  metadata_df <- read_parquet(cache_files$metadata)
} else {
  # If any of the data are not cached, load them from S3 and Athena.
  # Start by establishing an Athena connection with unload = TRUE so that
  # noctua parses arrays correctly
  noctua_options(unload = TRUE)
  athena_conn <- noctua::athena() %>%
    dbConnect(
      s3_staging_dir = "s3://ccao-athena-results-us-east-1",
      # Disable the Connections tab entry for this database, since we don't
      # need it for the purposes of this script and it causes connection setup
      # to take a long time by issuing a query for each table's schema
      rstudio_conn_tab = FALSE,
    )

  # Define base paths to S3 buckets where data are stored
  base_model_results_url <- "s3://ccao-model-results-us-east-1"
  base_dvc_url <- "s3://ccao-data-dvc-us-east-1"

  # Get the assessment year and predictor list for characteristic queries.
  # Assessment year is important since chars are defined for the year preceding
  # the lien date
  model_metadata_df <- dbGetQuery(
    conn = athena_conn,
    # This query should only ever return one row, but limit the results to 1
    # just to be defensive
    glue::glue(
      "SELECT assessment_data_year, model_predictor_all_name
      FROM model.metadata
      WHERE run_id = '{params$run_id}'
      LIMIT 1"
    )
  )
  assessment_data_year <- model_metadata_df %>% pull(assessment_data_year)
  all_predictors_raw <- model_metadata_df %>%
    pull(model_predictor_all_name) %>%
    unlist()
  # Replace school district GEOIDs with names
  all_predictors <- all_predictors_raw %>%
    replace(
      which(
        all_predictors_raw %in% c(
          "loc_school_elementary_district_geoid",
          "loc_school_secondary_district_geoid"
        )
      ),
      c(
        "loc_school_elementary_district_name",
        "loc_school_secondary_district_name"
      )
    )

  # Load final model run date for the given year, which might be different
  # from the run ID specified in the params object if the comps run was
  # not the same as the final model run
  #TODO: Potentially add this into another table for speed up?
  final_model_run_date <- dbGetQuery(
    conn = athena_conn,
    # As above, the LIMIT here is defensive
    glue::glue("
      SELECT run_id
      FROM model.final_model
      WHERE year = '{params$year}'
      AND type = 'res'
      AND is_final
      LIMIT 1
    ")
  ) %>%
    pull(run_id) %>%
    substr(1, 10) %>%
    as.Date()

  # Load card-level assessment data to use as the base for joining all chars
  assessment_df <- dbGetQuery(
    conn = athena_conn,
    glue::glue("
      SELECT * FROM z_ci_add_pinval_tables_default.pinval_assessment_card
      WHERE pin = '{params$pin}'
        AND year = '{params$year}'
        AND run_id = '{params$run_id}'
    ")
  ) %>% 
    mutate(
      township = ccao::town_convert(meta_township_code),
      # toTitleCase is nice here because it preserves lowercase for prepositions
      # like 'of' which are very common in municipality names
      municipality = loc_tax_municipality_name %>% tolower() %>% tools::toTitleCase(),
      bldg_sf = scales::comma(char_bldg_sf),
      land_sf = scales::comma(char_land_sf),
      pretty_pin = ccao::pin_format_pretty(pin)
    )
  
  subject_property_address <- assessment_df %>%
    pull(property_address)

  pred_pin_final_fmv_round <- assessment_df %>%
    pull(pred_pin_final_fmv_round)

  # Save model metadata to a dedicated list for ease of access.
  # Prefer a list to a dataframe since not all of the attribute values
  # have the same dimensions
  metadata_df <- tibble(
    final_model_run_date = final_model_run_date,
    subject_property_address = subject_property_address,
    pred_pin_final_fmv_round = assessment_df %>%
      pull(pred_pin_final_fmv_round),
    all_predictors = list(all_predictors)
  )

    comp_df <- dbGetQuery(
      conn = athena_conn,
      glue::glue("
        SELECT * FROM z_ci_add_pinval_tables_default.pinval_comp
        WHERE pin = '{params$pin}'
          AND year = '{params$year}'
          AND run_id = '{params$run_id}'
      ")
    )
    
    chars_to_recode <- comp_df %>%
    select(starts_with("char_") & !char_apts) %>%
    names()

    comp_df <- comp_df %>%
    # Translate coded vars to human readable values
    ccao::vars_recode(
      cols = chars_to_recode,
      type = "long",
      as_factor = FALSE
    ) %>% mutate(
      bldg_sf = scales::comma(char_bldg_sf),
      land_sf = scales::comma(char_land_sf),
      pretty_pin = ccao::pin_format_pretty(comp_pin),
      sale_date = as.Date(sale_date) %>%
        format("%b %Y")
    )
    
    
  #Write the assessment and comp data to the cache
  #write_parquet(assessment_df, cache_files$assessment)
  #write_parquet(comp_df, cache_files$comp)
  #write_parquet(metadata_df, cache_files$metadata)
}
```

The goal of this experimental report is to explain how the Cook County Assessor's statistical model estimated a subject home’s value. The `r format(metadata_df$final_model_run_date, "%Y")` model ran on **`r format(metadata_df$final_model_run_date, "%B %d, %Y")`**, and it used characteristics and sales available at that time to learn about the real estate market and estimate what the subject home would sell for if it sold on **January 1, `r format(metadata_df$final_model_run_date, "%Y")`**.

::: {.callout-tip collapse="true"}
## Click to read more about this report

This report attempts to explain the Assessor's model by explaining important inputs to the model: first, the subject home’s characteristics, and second, the top 5 experimental “sale comps.” These sale comps were identified by an experimental algorithm we built to answer the question “what sales did the model use to estimate my home’s value?” The end of the report shows the model’s estimated value for this property, which is based on the characteristics and sales input to the model.

The sales that the model used for estimation are reported by the Illinois Department of Revenue, which records sales using the [Real Estate Transfer Declaration form](https://tax.illinois.gov/content/dam/soi/en/web/tax/localgovernments/property/documents/ptax-203.pdf).

For more details on how the experimental sales comp algorithm works, see [Finding comparables with LightGBM](https://ccao-data.github.io/lightsnip/articles/finding-comps.html).
:::

```{r}
library(htmltools)

parcel_is_multicard <- nrow(assessment_df) > 1
if (parcel_is_multicard) {
  multicard_msg <- "This property has multiple \"cards\", which is an assessment term for a building or an improvement on a property. Each card on a property can have different characteristics, so the Assessor's model estimates different values for each card. Toggle between the tabs below to view characteristics and comparable sales for each card."
  tags$p(multicard_msg)
}
```

```{r output="asis"}
# This block takes the data generated by the previous block and displays them
# in the report. Since multicard PINs require rendering the same elements for
# different cards in a loop, we take the approach of generating HTML
# programmatically and rendering it using "asis" output and htmltools rather
# than writing Markdown directly. This is less typical for Quarto docs but
# helpful for producing nice output for multicard parcels.
library(knitr)
library(leaflet)
library(reactable)

# The main entrypoint function for rendering HTML elements from the data.
# Ties together a number of helper functions for returning specific data-driven
# elements like characteristic tables and a comps map.
#
# @param assessment_df Dataframe representing the chars for the subject parcel
# @param comp_df Dataframe representing chars for the comps
# @param parcel_is_multicard Boolean indicating a multicard property
# @return Returns a list of htmltools elements that can be rendered using `tagList()`
html_tags_for_report <- function(assessment_df, comp_df, parcel_is_multicard) {
  return(
    withTags(
      list(
        h2("Location"),
        location_char_table(assessment_df),
        h2("Characteristics"),
        property_char_table(assessment_df),
        h2("Top 5 comparable sales"),
        comps_map(assessment_df, comp_df, parcel_is_multicard),
        br(),
        combined_char_table(assessment_df, comp_df, parcel_is_multicard),
        subject_pin_sale_warning(comp_df, parcel_is_multicard),
        h2("Summary of comparable sales"),
        avg_price_summary(comp_df),
        h2("Initial model estimate"),
        pred_fmv_summary(assessment_df, parcel_is_multicard)
      )
    )
  )
}

# Helper function for generating a table with location characteristics for
# the subject property
location_char_table <- function(df) {
  return(
    df %>%
      select(
        Address = property_address,
        Municipality = municipality,
        "Assessor Township" = township,
        "Assessor Neighborhood" = meta_nbhd_code,
        "Elementary School District" = loc_school_elementary_district_name,
        "High School District" = loc_school_secondary_district_name
      ) %>%
      reactable(
        sortable = FALSE
      )
  )
}

# Helper function for generating a table with property characteristics for
# the subject property
property_char_table <- function(df) {
  return(
    df %>%
      select(
        "Class" = char_class,
        "Year Built" = char_yrblt,
        "Bldg. S.F." = bldg_sf,
        "Land S.F." = land_sf,
        Beds = char_beds,
        "Full Baths" = char_fbath,
        "Half Baths" = char_hbath
      ) %>%
      reactable(
        # Force left alignment, since otherwise numbers will be right aligned.
        # We want consistent alignment since this table always only has
        # one row
        defaultColDef = colDef(align = "left"),
        sortable = FALSE
      )
  )
}

# Helper function for generating a leaflet map of comparable sales
comps_map <- function(assessment_df, comp_df, parcel_is_multicard) {
  # Set the label of the subject property differently if it's multicard
  property_label <- glue::glue("Subject {ifelse(parcel_is_multicard, 'card', 'property')}")
  # Define legend attributes for the comps
  legend_labels <- c(
    property_label,
    "Comparable sale"
  )
  comp_color <- "#00cc00"
  circle_marker_styles <- "width: 13px; height: 13px; border-radius: 50%"
  legend_colors <- c(
    glue::glue("white; {circle_marker_styles}; border: 2px solid black"),
    glue::glue("{comp_color}; {circle_marker_styles}")
  )

  # Set a small buffer around the map bounds so that no parcel is clipped
  # when computing the bounds for the map based on parcel locations
  bounds_buffer <- 0.001

  # Generate the comps map
  leaflet() %>%
    addProviderTiles(providers$CartoDB.Positron) %>%
    # Start by adding a circle marker for the subject property with a label
    addCircleMarkers(
      data = assessment_df,
      ~loc_longitude,
      ~loc_latitude,
      opacity = 1,
      fill = FALSE,
      fillOpacity = 0,
      weight = 2,
      radius = 5,
      color = "black",
      # Don't display the label if the PIN is one of its own comps,
      # since we will use the comp to display the label in order to
      # show the most recent sale price/date.
      # Use a bare `if` statement because `ifelse` can't produce NULLs
      label = if (any(comp_df$is_subject_pin_sale)) {
        NULL
      } else {
        property_label
      },
      labelOptions = if (any(comp_df$is_subject_pin_sale)) {
        NULL
      } else {
        labelOptions(
          noHide = TRUE,
          textsize = "12px",
          direction = "top",
          offset = c(0, -4)
        )
      },
      # Don't display a popup if the PIN is one of its own comps,
      # since we will use the comp to display the popup in that case
      popup = ~ if (any(comp_df$is_subject_pin_sale)) {
        NULL
      } else {
        paste0(
          "<h5>", property_label, "</h5>",
          "<b>Address</b>: ", property_address,
          "<br><b>PIN</b>: ", link_pin(pin),
          "<br><b>Property class</b>: ", char_class,
          "<br><b>Assessor neighborhood</b>: ", meta_nbhd_code,
          "<br><b>Year built</b>: ", char_yrblt,
          "<br><b>Bldg S.F.</b>: ", bldg_sf,
          "<br><b>Land S.F.</b>: ", land_sf,
          "<br><b>Beds</b>: ", char_beds,
          "<br><b>Full baths</b>: ", char_fbath,
          "<br><b>Half baths</b>: ", char_hbath
        )
      }
    ) %>%
    # Add circle markers for the comps
    addCircleMarkers(
      data = comp_df,
      ~loc_longitude,
      ~loc_latitude,
      opacity = ~ ifelse(
        # Hide the marker if the comp has the same PIN as its target, since
        # we want to retain the marker styles of the target but override
        # the label
        is_subject_pin_sale,
        0,
        1
      ),
      fillOpacity = ~ ifelse(
        is_subject_pin_sale,
        0,
        1
      ),
      radius = 4,
      color = comp_color,
      label = ~ ifelse(
        is_subject_pin_sale,
        # It would be nice to introduce a line break here, but it doesn't
        # seem like the R leaflet package accepts HTML or exposes an interface
        # for advanced label formatting
        glue::glue("{property_label} [{sale_price_short} ({sale_date})]"),
        glue::glue("{sale_price_short} ({sale_date})")
      ),
      labelOptions = labelOptions(
        noHide = TRUE,
        textsize = "12px",
        direction = "top",
        opacity = 0.9,
        offset = c(0, -4)
      ),
      popup = ~ paste0(
        "<h5>",
        ifelse(
          is_subject_pin_sale,
          property_label,
          paste0("Comp ", comp_num)
        ),
        "</h5>",
        "<b>Address</b>: ", property_address,
        "<br><b>PIN</b>: ", link_pin(comp_pin),
        "<br><b>Property class</b>: ", char_class,
        "<br><b>Assessor neighborhood</b>: ", meta_nbhd_code,
        "<br><b>Sale price</b>: ", sale_price,
        "<br><b>Sale $/sqft</b>: ", sale_price_per_sq_ft,
        "<br><b>Sale date</b>: ", sale_date,
        "<br><b>Sale doc. num.</b>: ", comp_document_num,
        "<br><b>Year built</b>: ", char_yrblt,
        "<br><b>Bldg S.F.</b>: ", bldg_sf,
        "<br><b>Land S.F.</b>: ", land_sf,
        "<br><b>Beds</b>: ", char_beds,
        "<br><b>Full baths</b>: ", char_fbath,
        "<br><b>Half baths</b>: ", char_hbath
      )
    ) %>%
    addLegend(
      "bottomright",
      labels = legend_labels,
      colors = legend_colors,
      opacity = 1
    ) %>%
    addControl(
      "topright",
      html = "Tap or click on a dot for more details"
    ) %>%
    fitBounds(
      # Compute the bounds for the map based on the extent of the markers
      lng1 = min(assessment_df$loc_longitude, comp_df$loc_longitude) - bounds_buffer,
      lat1 = min(assessment_df$loc_latitude, comp_df$loc_latitude) - bounds_buffer,
      lng2 = max(assessment_df$loc_longitude, comp_df$loc_longitude) + bounds_buffer,
      lat2 = max(assessment_df$loc_latitude, comp_df$loc_latitude) + bounds_buffer
    )
}

# Helper function for generating a string summary of the average price of
# a dataframe of comps
avg_price_summary <- function(df) {
  # Compute the average price and the average price per square foot
  avg_sale_price <- df$meta_sale_price %>%
    mean() %>%
    scales::dollar()
  avg_price_per_sqft <- (df$meta_sale_price / df$char_bldg_sf) %>%
    mean() %>%
    scales::dollar(accuracy = 1)

  # Compute the range of dates for the sales, and get a rich text HTML string
  # describing the range
  sale_years <- comp_df %>%
    mutate(sale_year = substr(sale_date, 1, 4)) %>%
    arrange(sale_year) %>%
    pull(sale_year)
  sale_year_range_html <- ifelse(
    length(unique(sale_years)) > 1,
    glue::glue("between <b>{sale_years[1]} and {sale_years[length(sale_years)]}</b>"),
    glue::glue("in <b>{sale_years[1]}</b>")
  )

  return(
    HTML(
      paste0(
        "The top 5 comparable sales took place ", sale_year_range_html, ". ",
        "The average price of these sales was ",
        "<b>", avg_sale_price, "</b>",
        " at ",
        "<b>", avg_price_per_sqft, "/sq.ft.</b>",
        "</p>"
      )
    )
  )
}

# Helper function for generating a string summary of the predicted value of
# the subject property
pred_fmv_summary <- function(df, parcel_is_multicard) {
  # Use the initial FMV since we don't care about distinguishing building
  # from land value in this context
  pred_fmv <- df$pred_card_initial_fmv
  pred_fmv_per_sqft <- (pred_fmv / df$char_bldg_sf)

  return(
    HTML(
      paste0(
        "<p>",
        "Based on these and other sales, the model that ran on  ",
        format(metadata_df$final_model_run_date, "%B %d, %Y"),
        " initially estimated that the value of this ",
        ifelse(parcel_is_multicard, "card", "property"),
        " as of lien date ",
        "<b>January 1, ", format(metadata_df$final_model_run_date, "%Y"), "</b>",
        " should be ",
        "<b>", pred_fmv %>% scales::dollar(), "</b>",
        " at ",
        "<b>", pred_fmv_per_sqft %>% scales::dollar(accuracy = 1), "/sq.ft.</b>",
        "</p>"
      )
    )
  )
}

# Helper function to "freeze" rows in a paginated df with `rows_per_page`
# rows per page by taking `n` rows from the first page and
# copy/inserting them back into the df so they always appear as the first
# rows in the table. Useful hack for table libraries that don't allow you
# to freeze rows.
freeze_first_n_rows <- function(df, n = 2, rows_per_page = 10) {
  # Grab the rows that should be frozen
  frozen_rows <- df[1:n, ]

  # Initialize an empty dataframe to use for output
  new_df <- data.frame()

  # Calculate the sequence of indices that we will use to insert frozen rows
  df_len <- nrow(df)
  insert_indices <- seq(
    # Skip the first page of results
    rows_per_page + 1,
    df_len,
    # The step length for the sequence needs to account for the frozen rows that
    # we will insert
    rows_per_page - n
  )

  # Construct the output dataframe by iterating the rows in the input dataframe
  # and inserting the frozen rows where necessary
  for (i in 1:df_len) {
    if (i %in% insert_indices) {
      new_df <- bind_rows(new_df, frozen_rows)
    }
    new_df <- bind_rows(new_df, df[i, ])
  }

  return(new_df)
}

# Helper function for generating a table for comparing chars between the subject
# property and its comps
combined_char_table <- function(assessment_df, comp_df, parcel_is_multicard) {
  # Define a list of the most important characteristics to be displayed
  # first in the table
  top_chars <- c(
    "char_class", "meta_nbhd_code", "char_yrblt", "char_bldg_sf",
    "char_land_sf", "char_beds", "char_fbath", "char_hbath"
  )
  # Freeze this many of the top rows in the table
  num_frozen_rows <- 3
  rows_per_page <- 10

  return(
    assessment_df %>%
      mutate(
        comp_num = "0",
        meta_sale_document_num = NA_character_,
        sale_date = NA_character_,
        meta_sale_price = NA_real_,
        meta_sale_price_per_sq_ft = NA_real_
      ) %>%
      select(
        # If you change any chars in this list, make sure to double-check
        # the top_chars vector and add or remove chars as necessary so that
        # we don't accidentally add them via all_predictors
        comp_num,
        "Sale Price" = meta_sale_price,
        "Sale $/sqft" = meta_sale_price_per_sq_ft,
        "Sale Date" = sale_date,
        "Sale Doc. Num." = meta_sale_document_num,
        "Address" = property_address,
        "PIN" = pretty_pin,
        "Assessor Neighborhood" = meta_nbhd_code,
        all_of(top_chars),
        all_of(unlist(metadata_df$all_predictors) %>% setdiff(top_chars))
      ) %>%
      bind_rows(
        comp_df %>%
          # Add a marker to the comp number if it is a prior sale of the subject
          # card
          mutate(
            comp_num = as.character(comp_num),
            comp_num = ifelse(
              is_subject_pin_sale,
              paste0(comp_num, "*"),
              comp_num
            )
          ) %>%
          select(
            comp_num,
            "Sale Price" = sale_price,
            "Sale $/sqft" = sale_price_per_sq_ft,
            "Sale Date" = sale_date,
            "Sale Doc. Num." = comp_document_num,
            "Address" = property_address,
            "PIN" = pretty_pin,
            "Assessor Neighborhood" = meta_nbhd_code,
            all_of(top_chars),
            all_of(unlist(metadata_df$all_predictors) %>% setdiff(top_chars))
          )
      ) %>%
      # Truncate numeric values in the data to two decimal places
      mutate(across(where(is.numeric), ~ round(., 2))) %>%
      # Format numeric columns with commas but no decimals
      mutate(
        across(
          c(
            "char_bldg_sf", "char_land_sf", "time_sale_day",
            # Exclude number of foreclosures, which needs a decimal
            starts_with("prox_num") & !matches("prox_num_foreclosure_per_1000_pin_past_5_years"),
            ends_with("dist_ft")
          ),
          scales::label_comma(accuracy = 1)
        ),
      ) %>%
      # Format numeric columns with commas _and_ decimals
      mutate(prox_num_foreclosure_per_1000_pin_past_5_years = scales::comma(prox_num_foreclosure_per_1000_pin_past_5_years, accuracy = 0.01)) %>%
      # Format currency columns
      mutate(
        across(
          c(
            "acs5_median_household_renter_occupied_gross_rent",
            starts_with("acs5_median_income")
          ),
          scales::label_dollar()
        )
      ) %>%
      # Format percent columns
      mutate(across(starts_with("acs5_percent"), scales::label_percent())) %>%
      # This percent column is already multiplied by 100, it just needs a
      # percent sign
      mutate(other_tax_bill_rate = paste0(other_tax_bill_rate, "%")) %>%
      # Rename characteristic columns to their pretty format
      ccao::vars_rename(names_from = "model", names_to = "pretty") %>%
      rename("Number of Days Since First Recorded Sale" = "Sale Day") %>%
      # Pivot the dataframe longer so that we can use pagination to navigate
      # through multiple pages of full characteristic values.
      # Start by casting all columns to char ahead of pivot, since otherwise we
      # can't combine char values into one column
      mutate(across(everything(), as.character)) %>%
      pivot_longer(
        cols = -comp_num,
        names_to = "Characteristic",
        values_to = "Value"
      ) %>%
      # Pivot back to wide so that each property has its own column representing
      # all of its chars
      pivot_wider(
        names_from = comp_num,
        values_from = Value,
        names_prefix = "Comp "
      ) %>%
      rename_with(
        ~ ifelse(parcel_is_multicard, "Subject card", "Subject prop."),
        matches("Comp 0")
      ) %>%
      # Freeze the price char rows so that they are always visible in the table
      # even when viewing different pages
      freeze_first_n_rows(n = num_frozen_rows, rows_per_page = rows_per_page) %>%
      # Render a paginated table with results
      reactable(
        pagination = TRUE,
        defaultPageSize = rows_per_page,
        # Turn off sorting to retain the "frozen" price char rows
        sortable = FALSE,
        searchable = TRUE,
        columns = list(
          # Chars column should match the weight of the header row, to
          # emphasize that it's acting like a header
          Characteristic = colDef(style = list(fontWeight = 600))
        ),
        rowStyle = function(index) {
          # Style the frozen rows with a grey background and a harder bottom
          # border to visually indicate that they are frozen
          styles <- list()
          if (index %% 10 %in% 1:num_frozen_rows) {
            styles <- c(styles, background = "rgba(0, 0, 0, 0.05)")
          }
          if (index %% 10 == num_frozen_rows) {
            styles <- c(styles, "border-bottom" = "1px solid rgb(182, 182, 182)")
          }
          return(styles)
        },
        class = "cell-border stripe",
        highlight = TRUE,
        bordered = TRUE,
        defaultColDef = colDef(align = "center")
      )
  )
}

subject_pin_sale_warning <- function(comp_df, parcel_is_multicard) {
  if (any(comp_df$is_subject_pin_sale)) {
    return(
      HTML(
        paste0(
          "<b>*</b> This comparable is a sale of the subject ",
          ifelse(parcel_is_multicard, "card", "property"), ". ",
          "The model typically weights these sales highly, even if they ",
          "are older than other comparable sales."
        )
      )
    )
  }
}

if (parcel_is_multicard) {
  # In case of a multicard PIN, split the report out into tabsets, with one
  # tabset for each card. We have to do this in raw bootstrap because Quarto
  # tabsets aren't supported by htmltools::tagList, and we need tagList in order
  # to render the leaflet map, which can't otherwise be rendered in the context
  # of a `for` loop.

  # This list will store the nav elements that control the tab contents
  nav_tabs <- list()
  # This list will store the tab contents
  tab_contents <- list()

  for (card_num in assessment_df$meta_card_num) {
    # Filter the df for just the row representing the card at hand
    assessment_card_df <- assessment_df %>% filter(meta_card_num == card_num)
    # Filter for only this card's comps
    comp_card_df <- comp_df %>% filter(card == card_num)

    nav_tabs <- c(
      nav_tabs,
      withTags(
        list(
          li(
            class = "nav-item",
            role = "presentation",
            a(
              # Activate the first card's tab pane by default
              class = ifelse(card_num == 1, "nav-link active", "nav-link"),
              id = glue::glue("tabset-1-{card_num}-tab"),
              "data-bs-toggle" = "tab",
              "data-bs-target" = glue::glue("#tabset-1-{card_num}"),
              role = "tab",
              "aria-controls" = glue::glue("tabset-1-{card_num}"),
              "aria-selected" = ifelse(card_num == 1, "true", "false"),
              href = "",
              paste0("Card ", card_num)
            )
          )
        )
      )
    )

    tab_contents <- c(
      tab_contents,
      withTags(
        list(
          div(
            id = glue::glue("tabset-1-{card_num}"),
            class = ifelse(card_num == 1, "tab-pane active", "tab-pane"),
            role = "tabpanel",
            "aria-labelledby" = glue::glue("tabset-1-{card_num}-tab"),
            html_tags_for_report(assessment_card_df, comp_card_df, TRUE)
          )
        )
      )
    )
  }

  html_tags <- withTags(
    list(
      div(
        class = "panel-tabset",
        ul(
          class = "nav nav-tabs",
          role = "tablist",
          nav_tabs
        ),
        div(
          class = "tab-content",
          tab_contents
        )
      )
    )
  )
} else {
  # For single-card PINs, skip the tablist
  html_tags <- html_tags_for_report(assessment_df, comp_df, FALSE)
}

# Render the list of HTML tags
tagList(html_tags)
```

## Final model estimate

After rounding and other processing, the model's final estimate for the value of this property on lien date **January 1st, `r format(metadata_df$final_model_run_date, "%Y")`** was **`r scales::dollar(metadata_df$pred_pin_final_fmv_round)`**.

The model's estimated value for this property is not necessarily the final valuation during a reassessment. Analysts at the Assessor's Office can review the model's estimate and make adjustments. To see this property's most recent valuation, visit the `r link_pin(params$pin, "Assessor's website")`.
