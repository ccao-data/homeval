---
title: "Cook County Assessor’s Experimental Home Value Report"
date: "`r Sys.Date()`"
author: "Cook County Assessor's Office Data Department"
execute:
  echo: false
  warning: false
format:
  html:
    embed-resources: true
    fig-align: center
    fontsize: 12pt
knitr:
  opts_chunk:
    out.width: "100%"
editor: source
params:
  run_id: "2024-06-18-calm-nathan"
  year: "2024"
  pin: "05174150240000"
  num_comps: 5
---

```{r}
# Load dependencies and data for the selected parcel
library(arrow)
library(dplyr)
library(noctua)
library(tidyr)

# Helper function to turn strings to titlecase, inclusive of all caps strings
to_titlecase <- function(str) { return(str %>% tolower() %>% tools::toTitleCase()) }

# Helper function to add a link to a PIN
link_pin <- function(pin) {
  return(
    glue::glue(
      '<a target=_blank href=https://www.cookcountyassessor.com/pin/{pin}>{pin}</a>'
    )
  )
}

# Establish Athena connection
athena_conn <- noctua::athena() %>%
  dbConnect(s3_staging_dir="s3://ccao-athena-results-us-east-1")

# Define base paths to S3 buckets where data are stored
base_model_results_url <- "s3://ccao-model-results-us-east-1"
base_dvc_url <- "s3://ccao-data-dvc-us-east-1"
base_warehouse_url <- "s3://ccao-data-warehouse-us-east-1"

# Set prior year for characteristic queries
prior_year <- ((params$year %>% as.integer()) - 1) %>% as.character

# Load final model ID for this year
final_model_run_id <- dbGetQuery(
  conn = athena_conn,
  # This query should only ever return one value, but limit the results to 1
  # just to be defensive
  glue::glue("
    SELECT run_id
    FROM model.final_model
    WHERE year = '{params$year}'
    AND type = 'res'
    AND is_final
    LIMIT 1
  ")
) %>%
  pull(run_id)
final_model_run_date <- final_model_run_id %>% substr(1, 10) %>% as.Date()

# Load HIE data, which is stored separately from the assessment data
hie_df <- open_dataset(
  glue::glue("{base_warehouse_url}/ccao/other/hie/year=2020")
) %>%
  filter(pin == params$pin, hie_last_year_active >= params$year) %>%
  mutate(hie = TRUE) %>%
  select(pin, hie) %>%
  collect()

# Load school district data, for use in translating geo IDs to names
school_df <- dbGetQuery(
  conn = athena_conn,
  glue::glue("
    SELECT pin10, school_elementary_district_name, school_secondary_district_name
    FROM location.school
    WHERE pin10 = '{substr(params$pin, 1, 10)}'
    AND year = '{prior_year}'
  ")
) %>%
  mutate(across(starts_with("school_"), to_titlecase))

# Load property address, which is stored as part of the PIN-level assessment data
subject_property_address <- open_dataset(
  glue::glue(
    "{base_model_results_url}/assessment_pin/year={params$year}/run_id={params$run_id}"
  )
) %>%
  filter(
    meta_pin == params$pin,
    meta_year == prior_year
  ) %>%
  # Select only chars that are missing from card-level data
  select(loc_property_address) %>%
  collect() %>%
  mutate(property_address = to_titlecase(loc_property_address)) %>%
  pull(property_address)

# Load card-level assessment data to use as the base for joining all chars
assessment_df <- open_dataset(
  glue::glue(
    "{base_model_results_url}/assessment_card/year={params$year}/run_id={params$run_id}"
  )
) %>%
  filter(
    meta_pin == params$pin,
    meta_year == prior_year
  ) %>%
  collect() %>%
  # Join to the HIE data
  left_join(hie_df, by = c("meta_pin" = "pin")) %>%
  mutate(hie = ifelse(is.na(hie), "No", "Yes")) %>%
  # Join to school district data
  mutate(meta_pin10 = substr(meta_pin, 1, 10)) %>%
  left_join(school_df, by = c("meta_pin10" = "pin10")) %>%
  # Translate coded vars to human readable values
  ccao::vars_recode(
    cols = starts_with("char_"),
    type = "short",
    as_factor = FALSE
  ) %>%
  mutate(
    township = ccao::town_convert(meta_township_code),
    municipality = to_titlecase(loc_tax_municipality_name),
    bldg_sf = scales::comma(char_bldg_sf),
    land_sf = scales::comma(char_land_sf)
  )

# Load comp data
raw_comp_df <- open_dataset(
  glue::glue(
    "{base_model_results_url}/comp/year={params$year}/run_id={params$run_id}"
  )
) %>%
  filter(pin == params$pin) %>%
  collect()

# Pivot out the comp data and drop extraneous comps
pivoted_comp_df <- raw_comp_df %>%
  # This requires multiple pivots joined by bind_cols because the comp attribute
  # columns have different types, so they can't be pivoted in one operation.
  # Start by pivoting on comp_pin
  pivot_longer(
    starts_with("comp_pin_"),
    values_to = "comp_pin",
    names_to = "comp_num",
    names_pattern = "comp_pin_(\\d+)"
  ) %>%
  select(-starts_with("comp_score_"), -starts_with("comp_document_num_")) %>%
  bind_cols(
    # Next, pivot on comp_score and bind the resulting column to the dataframe
    raw_comp_df %>%
      pivot_longer(starts_with("comp_score_"), values_to = "comp_score") %>%
      select(comp_score),
    # Finally, pivot on comp_document_num and bind the column
    raw_comp_df %>%
      pivot_longer(
        starts_with("comp_document_num_"),
        values_to = "comp_document_num"
      ) %>%
      select(comp_document_num)
  ) %>%
  # Filter for only the top N comps
  mutate(comp_num = as.integer(comp_num)) %>%
  filter(comp_num <= params$num_comps)

# Load training data from the DVC cache to grab characteristics for comps
dvc_md5_hash <- read_parquet(
  glue::glue(
    "{base_model_results_url}/metadata/year={params$year}/{params$run_id}.parquet"
  )
) %>%
  pull(dvc_md5_training_data)

training_data_prefix <- dvc_md5_hash %>% substr(1, 2)
training_data_filename <- dvc_md5_hash %>% substr(3, nchar(dvc_md5_hash))

training_df <- open_dataset(
  glue::glue(
    "{base_dvc_url}/files/md5/{training_data_prefix}/{training_data_filename}"
  )
) %>%
  filter(
    meta_pin %in% pivoted_comp_df$comp_pin,
    meta_sale_document_num %in% pivoted_comp_df$comp_document_num
  ) %>%
  collect() %>%
  mutate(property_address = to_titlecase(loc_property_address))

# Attach training chars to comps
comp_df <- pivoted_comp_df %>%
  left_join(
    training_df,
    by = c(
      "comp_pin" = "meta_pin",
      "comp_document_num" = "meta_sale_document_num"
    )
  ) %>%
  # Translate coded vars to human readable values
  ccao::vars_recode(
    cols = starts_with("char_"),
    type = "short",
    as_factor = FALSE
  ) %>%
  mutate(
    bldg_sf = scales::comma(char_bldg_sf),
    land_sf = scales::comma(char_land_sf),
    sale_price = scales::dollar(meta_sale_price),
    sale_date = meta_sale_date %>% as.Date %>% format("%h %Y")
  )
```

## `r subject_property_address`

**Property ID: `r link_pin(params$pin)`**

This is an experimental home value report. The goal of this report is to explain how the statistical model predicted a subject home’s value. The `r format(final_model_run_date, "%Y")` model was run on `r format(final_model_run_date, "%B %d, %Y")`, and it used characteristics and sales available at that time to learn about the real estate market and estimate what the subject home would sell for if it sold on January 1, `r format(final_model_run_date, "%Y")`.

This report attempts to explain the model by explaining important inputs to the model: first, the subject home’s characteristics, and second, the top 5 experimental “sale comps.” These sale comps were identified by an experimental algorithm we built to answer the question “what sales did the model use to estimate my home’s value?” The end of the report shows the model’s predicted value for this property, which is based on the characteristics and sales input to the model.


```{r output="asis"}
library(ccao)
library(knitr)
library(kableExtra)
library(leaflet)

# Split assessment data so that we get one dataframe per card
assessment_dfs <- assessment_df %>% split(assessment_df %>% nrow() %>% seq_len())
is_multicard <- length(assessment_dfs) > 1

if (is_multicard) {
  # In case of a multicard PIN, split the report out into tabsets, with one
  # tabset for each card
  cat("::: {.panel-tabset}\n\n")
}

for (i in seq_along(assessment_dfs)) {
  assessment_card_df <- assessment_dfs[[i]]
  card_num <- assessment_card_df %>% pull(meta_card_num)
  comp_card_df <- comp_df %>%
    filter(card == card_num)
  
  if (is_multicard) {
    cat(glue::glue("### Card {card_num}\n\n"))
  }
  
  cat("<h3>Location</h3>\n\n")

  assessment_card_df %>%
    select(
      Township = township,
      Municipality = municipality,
      "Assessor Neighborhood" = meta_nbhd_code,
      "Elementary School District" = school_elementary_district_name,
      "High School District" = school_secondary_district_name
    ) %>%
    kable() %>%
    kable_styling(position = "left") %>%
    print()
  
  cat("<h3>Property</h3>\n\n")
  
  assessment_card_df %>%
    select(
      "Year Built" = char_yrblt,
      "Bldg. S.F." = bldg_sf,
      "Land S.F." = land_sf,
      Beds = char_beds,
      "Full Baths" = char_fbath,
      "Half Baths" = char_hbath,
      "Home Improvement Exemption" = hie
    ) %>%
    kable(align = c("r", "r", "r", "r", "r", "r", "l")) %>%
    kable_styling(position = "left") %>%
    print()
  
  cat("<h3>Top 5 comparable homes</h3>\n\n")
  
  comp_labels <- c(
    "Comp 1 (most similar)",
    paste0("Comp ", 2:4),
    "Comp 5 (least similar)"
  )
  
  leaflet_comp_df <- comp_card_df %>%
    mutate(comp_num_label = comp_labels[comp_num])
  
  color_palette <- colorFactor(
    c("#004d00", "#006600", "#008000", "#00cc00", "#99ff99"),
    comp_labels,
    ordered = TRUE
  )
  
  # TODO: Render this map using htmltools::tagList to get around
  # the fact that leaflet maps can't be rendered in loops (see
  # test.qmd for an example)
  leaflet() %>%
    addProviderTiles(providers$CartoDB.Positron) %>%
    addCircleMarkers(
      data = assessment_card_df,
      ~loc_longitude,
      ~loc_latitude,
      opacity = 1,
      fill = FALSE,
      fillOpacity = 0,
      weight = 2,
      radius = 5,
      color = "black",
      label = "Subject property",
      labelOptions = labelOptions(
        noHide = TRUE,
        textsize = "12px",
        direction = "top",
        offset = c(0, -4)
      )
    ) %>%
    addCircleMarkers(
      data = leaflet_comp_df,
      ~loc_longitude,
      ~loc_latitude,
      opacity = 1,
      fillOpacity = 1,
      radius = 4,
      color = ~ color_palette(comp_num_label),
      label = ~ glue::glue("{sale_price} ({sale_date})"),
      labelOptions = labelOptions(
        noHide = FALSE,
        textsize = "12px",
        direction = "top",
        offset = c(0, -4)
      ),
      popup = ~ paste0(
        "<b>Comp ", comp_num, "</b>",
        "<br><b>Address</b>: ", property_address,
        "<br><b>PIN</b>: ", link_pin(comp_pin),
        "<br><b>Class</b>: ", meta_class,
        "<hr>",
        "<b>Sale price</b>: ", sale_price,
        "<br><b>Sale date</b>: ", sale_date,
        "<br><b>Sale document number</b>: ", comp_document_num
      )
    ) %>%
    addLegend(
      "bottomright",
      pal = color_palette,
      values = comp_labels,
      opacity = 1
    ) %>%
    addControl(
      "topright",
      html = "Hover, click, or tap a dot for more details"
    ) %>%
    fitBounds(
      lng1 = min(comp_df$loc_longitude), lat1 = min(comp_df$loc_latitude),
      lng2 = max(comp_df$loc_longitude), lat2 = max(comp_df$loc_latitude)
    )
  
  avg_sale_price <- comp_df$meta_sale_price %>% mean() %>% scales::dollar()
  avg_price_per_sqft <- (comp_df$meta_sale_price / comp_df$char_bldg_sf) %>%
    mean() %>%
    scales::dollar(accuracy = 1)
  
  cat("<br>\n\n")
  cat(
    paste0(
      "The average sale price of the top 5 comparable properties was **",
      avg_sale_price,
      "** at **",
      avg_price_per_sqft,
      "/sq.ft.**\n\n"
    )
  )
  
  # Fix to account for the fact that kable incorrectly applies `table-responsive`
  # to the table element rather than its enclosing div when applying it as part
  # of the `bootstrap_options` param
  cat("::: {.table-responsive}\n\n")
  assessment_card_df %>%
    mutate(
      property_address = subject_property_address,
      comp_num = "",
      meta_sale_document_num = "",
      meta_sale_date = "",
      meta_sale_price = ""
    ) %>%
    select(
      "Comp Number" = comp_num,
      "Address" = property_address,
      "Property ID" = meta_pin,
      "Class" = meta_class,
      "Sale Document number" = meta_sale_document_num,
      "Sale Date" = meta_sale_date,
      "Sale Price" = meta_sale_price,
      "Year Built" = char_yrblt,
      "Bldg. S.F." = bldg_sf,
      "Land S.F." = land_sf,
      Beds = char_beds,
      "Full Baths" = char_fbath,
      "Half Baths" = char_hbath,
    ) %>%
    bind_rows(
      comp_card_df %>%
        # Cast comp num to character so we can join it with the missing value
        # symbols applied to the assessment data, which are stored as characters
        mutate(comp_num = as.character(comp_num)) %>%
        select(
          "Comp Number" = comp_num,
          "Address" = property_address,
          "Property ID" = comp_pin,
          "Class" = meta_class,
          "Sale Document number" = comp_document_num,
          "Sale Date" = sale_date,
          "Sale Price" = sale_price,
          "Year Built" = char_yrblt,
          "Bldg. S.F." = bldg_sf,
          "Land S.F." = land_sf,
          Beds = char_beds,
          "Full Baths" = char_fbath,
          "Half Baths" = char_hbath,
        )
    ) %>%
    kable(
      align = c(
        "l", "l", "l", "l", "r", "r", "r", "r", "r", "r", "r"
      )
    ) %>%
    kable_styling(position = "left") %>%
    print()
    cat(":::\n\n")
}

if (is_multicard) {
  cat(":::\n")
}
```
