---
title: "Cook County Assessor’s Experimental AutoAppraiser Report"
subtitle: "Property ID number: `r sprintf('<a target=_blank href=https://www.cookcountyassessor.com/pin/%s>%s</a>', params$pin, params$pin)`"
date: "`r Sys.Date()`"
author: "Cook County Assessor's Office Data Department"
execute:
  echo: false
  warning: false
format:
  html:
    embed-resources: true
    toc: true
    toc_float: true
    fig-align: center
    fontsize: 12pt
knitr:
  opts_chunk:
    out.width: "100%"
editor: source
params:
  run_id: "2024-06-18-calm-nathan"
  year: "2024"
  pin: "05174150240000"
  num_comps: 5
---

```{r}
# Load dependencies and data for the selected parcel
library(arrow)
library(dplyr)
library(noctua)
library(tidyr)

# Establish Athena connection
athena_conn <- dbConnect(noctua::athena())

# Define base paths to S3 buckets where data are stored
base_model_results_url <- "s3://ccao-model-results-us-east-1"
base_dvc_url <- "s3://ccao-data-dvc-us-east-1"
base_warehouse_url <- "s3://ccao-data-warehouse-us-east-1"

# Set prior year for characteristic queries
prior_year <- ((params$year %>% as.integer()) - 1) %>% as.character

# Load HIE data, which is stored separately from the assessment data
hie_df <- open_dataset(
  glue::glue("{base_warehouse_url}/ccao/other/hie/year=2020")
) %>%
  filter(pin == params$pin, hie_last_year_active >= params$year) %>%
  mutate(hie = TRUE) %>%
  select(pin, hie) %>%
  collect()

# Load school district data, for use in translating geo IDs to names
school_df <- dbGetQuery(
  conn = athena_conn,
  glue::glue("
    SELECT pin10, school_elementary_district_name, school_secondary_district_name
    FROM location.school
    WHERE pin10 = '{substr(params$pin, 1, 10)}'
    AND year = '{prior_year}'
  ")
)

# Load assessment data, which contains characteristics for the parcel
assessment_df <- open_dataset(
  glue::glue(
    "{base_model_results_url}/assessment_card/year={params$year}/run_id={params$run_id}"
  )
) %>%
  filter(
    meta_pin == params$pin,
    meta_year == prior_year
  ) %>%
  collect() %>%
  # Join to the HIE data
  left_join(hie_df, by = c("meta_pin" = "pin")) %>%
  mutate(hie = ifelse(is.na(hie), "No", "Yes")) %>%
  # Join to school district data
  mutate(meta_pin10 = substr(meta_pin, 1, 10)) %>%
  left_join(school_df, by = c("meta_pin10" = "pin10")) %>%
  # Translate coded vars to human readable values
  ccao::vars_recode(
    cols = starts_with("char_"),
    type = "short",
    as_factor = FALSE
  )

# Load comp data
raw_comp_df <- open_dataset(
  glue::glue(
    "{base_model_results_url}/comp/year={params$year}/run_id={params$run_id}"
  )
) %>%
  filter(pin == params$pin) %>%
  collect()

# Pivot out the comp data and drop extraneous comps
pivoted_comp_df <- raw_comp_df %>%
  # This requires multiple pivots joined by bind_cols because the comp attribute
  # columns have different types, so they can't be pivoted in one operation.
  # Start by pivoting on comp_pin
  pivot_longer(
    starts_with("comp_pin_"),
    values_to = "comp_pin",
    names_to = "comp_num",
    names_pattern = "comp_pin_(\\d+)"
  ) %>%
  select(-starts_with("comp_score_"), -starts_with("comp_document_num_")) %>%
  bind_cols(
    # Next, pivot on comp_score and bind the resulting column to the dataframe
    raw_comp_df %>%
      pivot_longer(starts_with("comp_score_"), values_to = "comp_score") %>%
      select(comp_score),
    # Finally, pivot on comp_document_num and bind the column
    raw_comp_df %>%
      pivot_longer(
        starts_with("comp_document_num_"),
        values_to = "comp_document_num"
      ) %>%
      select(comp_document_num)
  ) %>%
  # Filter for only the top N comps
  mutate(comp_num = as.integer(comp_num)) %>%
  filter(comp_num <= params$num_comps)

# Load training data from the DVC cache to grab characteristics for comps
dvc_md5_hash <- read_parquet(
  glue::glue(
    "{base_model_results_url}/metadata/year={params$year}/{params$run_id}.parquet"
  )
) %>%
  pull(dvc_md5_training_data)

training_data_prefix <- dvc_md5_hash %>% substr(1, 2)
training_data_filename <- dvc_md5_hash %>% substr(3, nchar(dvc_md5_hash))

training_df <- open_dataset(
  glue::glue(
    "{base_dvc_url}/files/md5/{training_data_prefix}/{training_data_filename}"
  )
) %>%
  filter(
    meta_pin %in% pivoted_comp_df$comp_pin,
    meta_sale_document_num %in% pivoted_comp_df$comp_document_num
  ) %>%
  collect()

# Attach training chars to comps
comp_df <- pivoted_comp_df %>%
  left_join(
    training_df,
    by = c(
      "comp_pin" = "meta_pin",
      "comp_document_num" = "meta_sale_document_num"
    )
  )
```

This is an experimental AutoAppraiser report. The goal of this report is to explain how the statistical model predicted a subject home’s value. The 2024 model was run on $final_model_run_date, and it used characteristics and sales available at that time to learn about the real estate market and estimate what the subject home would sell for if it sold on January 1, 2024.

This report attempts to explain the model by explaining important inputs to the model: first, the subject home’s characteristics, and second, the top 5 experimental “sale comps.” These sale comps were identified by an experimental algorithm we built to answer the question “what sales did the model use to estimate my home’s value?” The end of the report shows the model’s predicted value for this property, which is based on the characteristics and sales input to the model.

### 744 Prospect Ave, Winnetka

#### Location

```{r}
library(ccao)
library(knitr)
library(kableExtra)

assessment_df %>%
  mutate(township = ccao::town_convert(meta_township_code)) %>%
  select(
    Card = meta_card_num,
    Township = township,
    Municipality = loc_tax_municipality_name,
    "Assessor Neighborhood" = meta_nbhd_code,
    "Elementary School District" = school_elementary_district_name,
    "High School District" = school_secondary_district_name
  ) %>%
  kable() %>%
  kable_styling(
    "striped",
    position = "left",
    fixed_thead = TRUE
  )
```

#### Property

```{r}
assessment_df %>%
  select(
    "Year Built" = char_yrblt,
    "Bldg. S.F." = char_bldg_sf,
    "Land S.F." = char_land_sf,
    Beds = char_beds,
    "Full Baths" = char_fbath,
    "Half Baths" = char_hbath,
    "Home Improvement Exemption" = hie
  ) %>%
  kable() %>%
  kable_styling(
    "striped",
    position = "left",
    fixed_thead = TRUE
  )
```

#### Top 5 comparable homes

_TK: Comps map + characteristic table_
