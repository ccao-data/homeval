---
title: "Cook County Assessor’s Experimental PINVAL Report"
date: "`r Sys.Date()`"
author: "Cook County Assessor's Office Data Department"
execute:
  echo: false
  warning: false
format:
  html:
    embed-resources: true
    fig-align: center
    fontsize: 12pt
    grid:
      # Add a little more width to the body so the char table is full width
      body-width: 1000px
knitr:
  opts_chunk:
    out.width: "100%"
editor: source
params:
  run_id: "2024-06-18-calm-nathan"
  year: "2024"
  # Good PINs for testing:
  #   * Single card: 14051280390000
  #   * Multicard: 16251020210000
  #   * Past sale is a comp: 14331000240000
  pin: "14331000240000"
  num_comps: 5
---

```{r}
# This block loads data for the selected parcel, year, and model run.
# Start by loading R dependencies
library(arrow)
library(ccao)
library(dplyr)
library(noctua)
library(stringr)
library(tidyr)
library(tools)

# Helper function to wrap a PIN in a link for display purposes
link_pin <- function(pin) {
  pretty_pin <- ccao::pin_format_pretty(pin)
  return(
    glue::glue(
      "<a target=_blank href=https://www.cookcountyassessor.com/pin/{pin}>{pretty_pin}</a>"
    )
  )
}

# Check if this PIN/year combo is cached, and skip data loading if so
base_cache_file_path <- glue::glue("cache/{params$pin}-{params$year}")
cache_files <- list(
  assessment = glue::glue("{base_cache_file_path}-asmt.parquet"),
  comp = glue::glue("{base_cache_file_path}-comp.parquet"),
  metadata = glue::glue("{base_cache_file_path}-meta.parquet")
)

if (cache_files %>% sapply(file.exists) %>% all()) {
  assessment_df <- read_parquet(cache_files$assessment)
  comp_df <- read_parquet(cache_files$comp)
  metadata_df <- read_parquet(cache_files$metadata)
} else {
  # If any of the data are not cached, load them from S3 and Athena.
  # Start by establishing an Athena connection
  athena_conn <- noctua::athena() %>%
    dbConnect(s3_staging_dir = "s3://ccao-athena-results-us-east-1")

  # Define base paths to S3 buckets where data are stored
  base_model_results_url <- "s3://ccao-model-results-us-east-1"
  base_dvc_url <- "s3://ccao-data-dvc-us-east-1"

  # Get the assessment year for characteristic queries, since chars are
  # defined for the year preceding the lien date
  assessment_data_year <- dbGetQuery(
    conn = athena_conn,
    # This query should only ever return one value, but limit the results to 1
    # just to be defensive
    glue::glue(
      "SELECT assessment_data_year
      FROM model.metadata
      WHERE run_id = '{params$run_id}'
      LIMIT 1"
    )
  ) %>%
    pull(assessment_data_year)

  # Load final model run date for the given year, which might be different
  # from the run ID specified in the params object if the comps run was
  # not the same as the final model run
  final_model_run_date <- dbGetQuery(
    conn = athena_conn,
    # As above, the LIMIT here is defensive
    glue::glue("
      SELECT run_id
      FROM model.final_model
      WHERE year = '{params$year}'
      AND type = 'res'
      AND is_final
      LIMIT 1
    ")
  ) %>%
    pull(run_id) %>%
    substr(1, 10) %>%
    as.Date()

  # Load chars that are stored in the PIN-level assessment data
  assessment_pin_df <- open_dataset(
    glue::glue(
      "{base_model_results_url}/assessment_pin/year={params$year}/run_id={params$run_id}"
    )
  ) %>%
    filter(
      meta_pin == params$pin,
      meta_year == assessment_data_year
    ) %>%
    collect()

  subject_property_address <- assessment_pin_df %>%
    # str_to_title is nice for addresses because it preserves the capitalization
    # of directionals like 'N' or 'W'
    mutate(property_address = loc_property_address %>% tolower() %>% str_to_title()) %>%
    pull(property_address)

  hie <- assessment_pin_df %>%
    mutate(hie = flag_hie_num_expired %>% as.logical() %>% ifelse("Yes", "No")) %>%
    pull(hie)

  # Save model metadata to a dedicated dataframe for ease of access
  metadata_df <- data.frame(
    final_model_run_date = final_model_run_date,
    subject_property_address = subject_property_address
  )

  # Load school district data, for use in translating geo IDs to names
  school_df <- dbGetQuery(
    conn = athena_conn,
    glue::glue("
      SELECT pin10, school_elementary_district_name, school_secondary_district_name
      FROM location.school
      WHERE pin10 = '{substr(params$pin, 1, 10)}'
      AND year = '{assessment_data_year}'
    ")
  )

  # Load card-level assessment data to use as the base for joining all chars
  assessment_df <- open_dataset(
    glue::glue(
      "{base_model_results_url}/assessment_card/year={params$year}/run_id={params$run_id}"
    )
  ) %>%
    filter(
      meta_pin == params$pin,
      meta_year == assessment_data_year
    ) %>%
    collect() %>%
    # Join to school district data
    mutate(meta_pin10 = substr(meta_pin, 1, 10)) %>%
    left_join(school_df, by = c("meta_pin10" = "pin10")) %>%
    # Translate coded vars to human readable values
    ccao::vars_recode(
      cols = starts_with("char_"),
      type = "short",
      as_factor = FALSE
    ) %>%
    mutate(
      township = ccao::town_convert(meta_township_code),
      # toTitleCase is nice here because it preserves lowercase for prepositions
      # like 'of' which are very common in municipality names
      municipality = loc_tax_municipality_name %>% tolower() %>% tools::toTitleCase(),
      bldg_sf = scales::comma(char_bldg_sf),
      land_sf = scales::comma(char_land_sf),
      pretty_pin = ccao::pin_format_pretty(meta_pin),
      # Attach PIN-level chars to all cards
      property_address = subject_property_address,
      hie = hie
    )

  # Load comp data
  raw_comp_df <- open_dataset(
    glue::glue(
      "{base_model_results_url}/comp/year={params$year}/run_id={params$run_id}"
    )
  ) %>%
    filter(pin == params$pin) %>%
    collect()

  # Pivot out the comp data and drop extraneous comps
  pivoted_comp_df <- raw_comp_df %>%
    # This requires multiple pivots joined by bind_cols because the comp attribute
    # columns have different types, so they can't be pivoted in one operation.
    # Start by pivoting on comp_pin
    pivot_longer(
      starts_with("comp_pin_"),
      values_to = "comp_pin",
      names_to = "comp_num",
      names_pattern = "comp_pin_(\\d+)"
    ) %>%
    select(-starts_with("comp_score_"), -starts_with("comp_document_num_")) %>%
    bind_cols(
      # Next, pivot on comp_score and bind the resulting column to the dataframe
      raw_comp_df %>%
        pivot_longer(starts_with("comp_score_"), values_to = "comp_score") %>%
        select(comp_score),
      # Finally, pivot on comp_document_num and bind the column
      raw_comp_df %>%
        pivot_longer(
          starts_with("comp_document_num_"),
          values_to = "comp_document_num"
        ) %>%
        select(comp_document_num)
    ) %>%
    # Filter for only the top N comps
    mutate(comp_num = as.integer(comp_num)) %>%
    filter(comp_num <= params$num_comps)

  # Load training data from the DVC cache to grab characteristics for comps
  dvc_md5_hash <- read_parquet(
    glue::glue(
      "{base_model_results_url}/metadata/year={params$year}/{params$run_id}.parquet"
    )
  ) %>%
    pull(dvc_md5_training_data)

  training_data_prefix <- dvc_md5_hash %>% substr(1, 2)
  training_data_filename <- dvc_md5_hash %>% substr(3, nchar(dvc_md5_hash))

  training_df <- open_dataset(
    glue::glue(
      "{base_dvc_url}/files/md5/{training_data_prefix}/{training_data_filename}"
    )
  ) %>%
    filter(
      meta_pin %in% pivoted_comp_df$comp_pin,
      meta_sale_document_num %in% pivoted_comp_df$comp_document_num
    ) %>%
    collect() %>%
    mutate(property_address = loc_property_address %>% tolower() %>% str_to_title())

  # Attach training chars to comps
  comp_df <- pivoted_comp_df %>%
    left_join(
      training_df,
      by = c(
        "comp_pin" = "meta_pin",
        "comp_document_num" = "meta_sale_document_num"
      )
    ) %>%
    # Translate coded vars to human readable values
    ccao::vars_recode(
      cols = starts_with("char_"),
      type = "short",
      as_factor = FALSE
    ) %>%
    mutate(
      bldg_sf = scales::comma(char_bldg_sf),
      land_sf = scales::comma(char_land_sf),
      sale_price = scales::dollar(meta_sale_price),
      sale_price_short = scales::dollar(
        meta_sale_price,
        accuracy = 1,
        scale = 1 / 1000,
        suffix = "K"
      ),
      sale_price_per_sq_ft = (meta_sale_price / char_bldg_sf) %>%
        scales::dollar(accuracy = 1),
      sale_date = meta_sale_date %>% as.Date() %>% format("%h %Y"),
      pretty_pin = ccao::pin_format_pretty(comp_pin)
    )

  # Write the assessment and comp data to the cache
  write_parquet(assessment_df, cache_files$assessment)
  write_parquet(comp_df, cache_files$comp)
  write_parquet(metadata_df, cache_files$metadata)
}
```

This is an experimental home value report. The goal of this report is to explain how the Cook County Assessor's statistical model predicted a subject home’s value. The `r format(metadata_df$final_model_run_date, "%Y")` model was run on **`r format(metadata_df$final_model_run_date, "%B %d, %Y")`**, and it used characteristics and sales available at that time to learn about the real estate market and estimate what the subject home would sell for if it sold on **January 1, `r format(metadata_df$final_model_run_date, "%Y")`**. The sales that the model used for estimation are reported by the Illinois Department of Revenue, which records sales using the [Real Estate Transfer Declaration form](https://tax.illinois.gov/content/dam/soi/en/web/tax/localgovernments/property/documents/ptax-203.pdf).

This report attempts to explain the Assessor's model by explaining important inputs to the model: first, the subject home’s characteristics, and second, the top 5 experimental “sale comps.” These sale comps were identified by an experimental algorithm we built to answer the question “what sales did the model use to estimate my home’s value?” The end of the report shows the model’s predicted value for this property, which is based on the characteristics and sales input to the model.

For more details on how the experimental sales comp algorithm works, see [Finding comparables with LightGBM](https://ccao-data.github.io/lightsnip/articles/finding-comps.html).

## `r metadata_df$subject_property_address`

**Property ID: `r link_pin(params$pin)`**

```{r}
library(htmltools)

parcel_is_multicard <- nrow(assessment_df) > 1
if (parcel_is_multicard) {
  multicard_msg <- "This property has multiple \"cards\", which is an assessment term for a building or an improvement on a property. Each card on a property can have different characteristics, so the Assessor's model predicts different values for each card. Toggle between the tabs below to view characteristics and comparable sales for each card."
  tags$p(multicard_msg)
}
```

```{r output="asis"}
# This block takes the data generated by the previous block and displays them
# in the report. Since multicard PINs require rendering the same elements for
# different cards in a loop, we take the approach of generating HTML
# programmatically and rendering it using "asis" output and htmltools rather
# than writing Markdown directly. This is less typical for Quarto docs but
# helpful for producing nice output for multicard parcels.
library(DT)
library(knitr)
library(kableExtra)
library(leaflet)

# The main entrypoint function for rendering HTML elements from the data.
# Ties together a number of helper functions for returning specific data-driven
# elements like characteristic tables and a comps map.
#
# @param assessment_df Dataframe representing the chars for the subject parcel
# @param comp_df Dataframe representing chars for the comps
# @return Returns a list of htmltools elements that can be rendered using `tagList()`
html_tags_for_report <- function(assessment_df, comp_df) {
  return(
    withTags(
      list(
        h3("Location"),
        location_char_table(assessment_df),
        h3("Property"),
        property_char_table(assessment_df),
        h3("Top 5 comparable homes"),
        comps_map(assessment_df, comp_df),
        br(),
        div(
          # kable incorrectly applies `table-responsive` to the table element
          # rather than its enclosing div when applying it as part of the
          # `bootstrap_options` param, so we need to set the class on an
          # enclosing div in order to prevent the table from breaking the width
          # of the viewport
          class = "table-responsive",
          combined_char_table(assessment_df, comp_df)
        ),
        avg_price_summary(comp_df),
        pred_fmv_summary(assessment_df)
      )
    )
  )
}

# Helper function for generating a table with location characteristics for
# the subject property
location_char_table <- function(df) {
  return(
    # Mark the kable output as an HTML string so that htmltools doesn't
    # attempt to process it
    HTML(
      df %>%
        select(
          "Assessor Township" = township,
          "Assessor Neighborhood" = meta_nbhd_code,
          Municipality = municipality,
          "Elementary School District" = school_elementary_district_name,
          "High School District" = school_secondary_district_name
        ) %>%
        kable(
          # Prevent Quarto from processing the table, which can produce
          # garbled HTML in the case of multicard parcels
          table.attr = "data-quarto-disable-processing='true' class='table'",
          format = "html"
        )
    )
  )
}

# Helper function for generating a table with property characteristics for
# the subject property
property_char_table <- function(df) {
  return(
    HTML(
      df %>%
        select(
          "Class" = char_class,
          "Year Built" = char_yrblt,
          "Bldg. S.F." = bldg_sf,
          "Land S.F." = land_sf,
          Beds = char_beds,
          "Full Baths" = char_fbath,
          "Half Baths" = char_hbath
        ) %>%
        kable(
          # Force left alignment, since otherwise numbers will be right aligned.
          # We want consistent alignment since this table always only has
          # one row
          align = c("l", "l", "l", "l", "l", "l", "l"),
          table.attr = "data-quarto-disable-processing='true' class='table'",
          format = "html"
        )
    )
  )
}

# Helper function for generating a leaflet map of comparable sales
comps_map <- function(assessment_df, comp_df) {
  # Define human-readable labels for the comps
  comp_labels <- c(
    "Comp 1 (most similar)",
    paste0("Comp ", 2:4),
    "Comp 5 (least similar)"
  )

  # Define a color palette that leaflet will use to distinguish between
  # different levels of comps
  color_palette <- colorFactor(
    c("#004d00", "#006600", "#008000", "#00cc00", "#99ff99"),
    comp_labels,
    ordered = TRUE
  )

  # Set a small buffer around the map bounds so that no parcel is clipped
  # when computing the bounds for the map based on parcel locations
  bounds_buffer <- 0.001

  # Generate the comps map
  leaflet() %>%
    addProviderTiles(providers$CartoDB.Positron) %>%
    # Start by adding a circle marker for the subject property with a label
    addCircleMarkers(
      data = assessment_df,
      ~loc_longitude,
      ~loc_latitude,
      opacity = 1,
      fill = FALSE,
      fillOpacity = 0,
      weight = 2,
      radius = 5,
      color = "black",
      # Don't display the label if the PIN is one of its own comps,
      # since we will use the comp to display the label in order to
      # show the most recent sale price/date.
      # Use a bare `if` statement because `ifelse` can't produce NULLs
      label = if (params$pin %in% comp_df$comp_pin) {
        NULL
      } else {
        "Subject property"
      },
      labelOptions = if (params$pin %in% comp_df$comp_pin) {
        NULL
      } else {
        labelOptions(
          noHide = TRUE,
          textsize = "12px",
          direction = "top",
          offset = c(0, -4)
        )
      },
      # Don't display a popup if the PIN is one of its own comps,
      # since we will use the comp to display the popup in that case
      popup = ~ if (params$pin %in% comp_df$comp_pin) {
        NULL
      } else {
        paste0(
          "<h5>Subject property</h5>",
          "<b>Address</b>: ", property_address,
          "<br><b>Property ID</b>: ", link_pin(meta_pin),
          "<br><b>Property class</b>: ", char_class,
          "<br><b>Assessor neighborhood</b>: ", meta_nbhd_code,
          "<br><b>Year built</b>: ", char_yrblt,
          "<br><b>Bldg S.F.</b>: ", bldg_sf,
          "<br><b>Land S.F.</b>: ", land_sf,
          "<br><b>Beds</b>: ", char_beds,
          "<br><b>Full baths</b>: ", char_fbath,
          "<br><b>Half baths</b>: ", char_hbath
        )
      }
    ) %>%
    # Add circle markers for the comps
    addCircleMarkers(
      data = comp_df %>%
        mutate(comp_num_label = comp_labels[comp_num]),
      ~loc_longitude,
      ~loc_latitude,
      opacity = ~ ifelse(
        # Hide the marker if the comp has the same PIN as its target, since
        # we want to retain the marker styles of the target but override
        # the label
        comp_pin == params$pin,
        0,
        1
      ),
      fillOpacity = ~ ifelse(
        comp_pin == params$pin,
        0,
        1
      ),
      radius = 4,
      color = ~ color_palette(comp_num_label),
      label = ~ ifelse(
        comp_pin == params$pin,
        # It would be nice to introduce a line break here, but it doesn't
        # seem like the R leaflet package accepts HTML or exposes an interface
        # for advanced label formatting
        glue::glue("Subject property [{sale_price_short} ({sale_date})]"),
        glue::glue("{sale_price_short} ({sale_date})")
      ),
      labelOptions = labelOptions(
        noHide = TRUE,
        textsize = "12px",
        direction = "top",
        opacity = 0.9,
        offset = c(0, -4)
      ),
      popup = ~ paste0(
        "<h5>",
        ifelse(
          comp_pin == params$pin,
          "Subject property",
          paste0("Comp ", comp_num)
        ),
        "</h5>",
        "<b>Address</b>: ", property_address,
        "<br><b>Property ID</b>: ", link_pin(comp_pin),
        "<br><b>Property class</b>: ", char_class,
        "<br><b>Assessor neighborhood</b>: ", meta_nbhd_code,
        "<br><b>Sale price</b>: ", sale_price,
        "<br><b>Sale $/sqft</b>: ", sale_price_per_sq_ft,
        "<br><b>Sale date</b>: ", sale_date,
        "<br><b>Sale doc. num.</b>: ", comp_document_num,
        "<br><b>Year built</b>: ", char_yrblt,
        "<br><b>Bldg S.F.</b>: ", bldg_sf,
        "<br><b>Land S.F.</b>: ", land_sf,
        "<br><b>Beds</b>: ", char_beds,
        "<br><b>Full baths</b>: ", char_fbath,
        "<br><b>Half baths</b>: ", char_hbath
      )
    ) %>%
    addLegend(
      "bottomright",
      pal = color_palette,
      values = comp_labels,
      opacity = 1
    ) %>%
    addControl(
      "topright",
      html = "Tap or click on a dot for more details"
    ) %>%
    fitBounds(
      # Compute the bounds for the map based on the extent of the markers
      lng1 = min(assessment_df$loc_longitude, comp_df$loc_longitude) - bounds_buffer,
      lat1 = min(assessment_df$loc_latitude, comp_df$loc_latitude) - bounds_buffer,
      lng2 = max(assessment_df$loc_longitude, comp_df$loc_longitude) + bounds_buffer,
      lat2 = max(assessment_df$loc_latitude, comp_df$loc_latitude) + bounds_buffer
    )
}

# Helper function for generating a string summary of the average price of
# a dataframe of comps
avg_price_summary <- function(df) {
  avg_sale_price <- df$meta_sale_price %>%
    mean() %>%
    scales::dollar()
  avg_price_per_sqft <- (df$meta_sale_price / df$char_bldg_sf) %>%
    mean() %>%
    scales::dollar(accuracy = 1)

  return(
    HTML(
      paste0(
        "<p style='padding-top: 1em'>",
        "The average sale price of the top 5 comparable homes was ",
        "<b>", avg_sale_price, "</b>",
        " at ",
        "<b>", avg_price_per_sqft, "/sq.ft.</b> ",
        "</p>"
      )
    )
  )
}

# Helper function for generating a string summary of the predicted value of
# the subject property
pred_fmv_summary <- function(df) {
  # Use the initial FMV since we don't care about distinguishing building
  # from land value in this context
  pred_fmv <- df$pred_card_initial_fmv
  pred_fmv_per_sqft <- (pred_fmv / df$char_bldg_sf)

  return(
    HTML(
      paste0(
        "<p>",
        "Based on these and other sales, the model that ran on  ",
        format(metadata_df$final_model_run_date, "%B %d, %Y"),
        " predicted that the value of this home as of lien date January 1, ",
        format(metadata_df$final_model_run_date, "%Y"),
        " should be ",
        "<b>", pred_fmv %>% scales::dollar(), "</b>",
        " at ",
        "<b>", pred_fmv_per_sqft %>% scales::dollar(accuracy = 1), "/sq.ft.</b>",
        "</p>"
      )
    )
  )
}

# Helper function for generating a table for comparing chars between the subject
# property and its comps
combined_char_table <- function(assessment_df, comp_df) {
  return(
    assessment_df %>%
      mutate(
        comp_num = 0,
        meta_sale_document_num = "",
        meta_sale_date = "",
        meta_sale_price = "",
        meta_sale_price_per_sq_ft = "",
      ) %>%
      select(
        comp_num,
        "Address" = property_address,
        "Property ID" = pretty_pin,
        "Property Class" = char_class,
        "Assessor Neighborhood" = meta_nbhd_code,
        "Sale Price" = meta_sale_price,
        "Sale $/sqft" = meta_sale_price_per_sq_ft,
        "Sale Date" = meta_sale_date,
        "Sale Doc. Num." = meta_sale_document_num,
        "Year Built" = char_yrblt,
        "Bldg. S.F." = bldg_sf,
        "Land S.F." = land_sf,
        Beds = char_beds,
        "Full Baths" = char_fbath,
        "Half Baths" = char_hbath
      ) %>%
      bind_rows(
        comp_df %>%
          select(
            comp_num,
            "Address" = property_address,
            "Property ID" = pretty_pin,
            "Property Class" = char_class,
            "Assessor Neighborhood" = meta_nbhd_code,
            "Sale Price" = sale_price,
            "Sale $/sqft" = sale_price_per_sq_ft,
            "Sale Date" = sale_date,
            "Sale Doc. Num." = comp_document_num,
            "Year Built" = char_yrblt,
            "Bldg. S.F." = bldg_sf,
            "Land S.F." = land_sf,
            Beds = char_beds,
            "Full Baths" = char_fbath,
            "Half Baths" = char_hbath
          )
      ) %>%
      # Pivot the dataframe longer so that we can use pagination to navigate
      # through multiple pages of full characteristic values.
      # Start by casting all columns to char ahead of pivot, since otherwise we
      # can't combine char values into one column
      mutate(across(-comp_num, as.character)) %>%
      pivot_longer(
        cols = -comp_num,
        names_to = "Characteristic",
        values_to = "Value"
      ) %>%
      # Pivot back to wide so that each property has its own column representing
      # all of its chars
      pivot_wider(
        names_from = comp_num,
        values_from = Value,
        names_prefix = "Comp "
      ) %>%
      rename("Subj. prop." = "Comp 0") %>%
      datatable(
        options = list(
          autoWidth = TRUE,
          className = "cell-border stripe",
          pageLength = 10,
          dom = "tp", # Show just table and pagination controls
          columnDefs = list(
            list(className = "dt-center", targets = "_all")
          )
        )
      ) %>%
      formatStyle("Characteristic", fontWeight = "bold")
  )
}

if (parcel_is_multicard) {
  # In case of a multicard PIN, split the report out into tabsets, with one
  # tabset for each card. We have to do this in raw bootstrap because Quarto
  # tabsets aren't supported by htmltools::tagList, and we need tagList in order
  # to render the leaflet map, which can't otherwise be rendered in the context
  # of a `for` loop.

  # This list will store the nav elements that control the tab contents
  nav_tabs <- list()
  # This list will store the tab contents
  tab_contents <- list()

  for (card_num in assessment_df$meta_card_num) {
    # Filter the df for just the row representing the card at hand
    assessment_card_df <- assessment_df %>% filter(meta_card_num == card_num)
    # Filter for only this card's comps
    comp_card_df <- comp_df %>% filter(card == card_num)

    nav_tabs <- c(
      nav_tabs,
      withTags(
        list(
          li(
            class = "nav-item",
            role = "presentation",
            a(
              # Activate the first card's tab pane by default
              class = ifelse(card_num == 1, "nav-link active", "nav-link"),
              id = glue::glue("tabset-1-{card_num}-tab"),
              "data-bs-toggle" = "tab",
              "data-bs-target" = glue::glue("#tabset-1-{card_num}"),
              role = "tab",
              "aria-controls" = glue::glue("tabset-1-{card_num}"),
              "aria-selected" = ifelse(card_num == 1, "true", "false"),
              href = "",
              paste0("Card ", card_num)
            )
          )
        )
      )
    )

    tab_contents <- c(
      tab_contents,
      withTags(
        list(
          div(
            id = glue::glue("tabset-1-{card_num}"),
            class = ifelse(card_num == 1, "tab-pane active", "tab-pane"),
            role = "tabpanel",
            "aria-labelledby" = glue::glue("tabset-1-{card_num}-tab"),
            html_tags_for_report(assessment_card_df, comp_card_df)
          )
        )
      )
    )
  }

  html_tags <- withTags(
    list(
      div(
        class = "panel-tabset",
        ul(
          class = "nav nav-tabs",
          role = "tablist",
          nav_tabs
        ),
        div(
          class = "tab-content",
          tab_contents
        )
      )
    )
  )
} else {
  # For single-card PINs, skip the tablist
  html_tags <- html_tags_for_report(assessment_df, comp_df)
}

# Render the list of HTML tags
tagList(html_tags)
```
