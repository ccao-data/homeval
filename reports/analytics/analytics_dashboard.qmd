---
title: "HomeVal Analytics"
execute:
  echo: false
  warning: false
  message: false
params:
  # Dates must be inserted as YYYY-MM-DD.
  # Lists of IP's or excluded dates are prefixed by '-'.
  # All params are optional and will default
  # to querying the first day of data to the
  # current day.
  start_date:
  excluded_dates:
  end_date:
  refresh_today:
  ip_addresses_to_filter:
format:
  html:
    embed-resources: true
    grid:
      body-width: 1000px

---

```{r}
library(arrow)
library(DBI)
library(dplyr)
library(fs)
library(glue)
library(leaflet)
library(lubridate)
library(paws)
library(plotly)
library(purrr)
library(tibble)
library(tidyverse)
library(urltools)
library(uaparserjs)
```

```{r convert_params}
tz_local <- "America/Chicago"

# Set start day to the first day of data unless otherwise specified
start_date <- as.Date(ifelse(
  is.null(params$start_date),
  "2025-09-04",
  params$start_date
))

# Set the end day to today unless otherwise specified.
end_date <- as.Date(ifelse(
  is.null(params$end_date),
  today(tzone = tz_local),
  params$end_date
))
```


```{r download_assessment_card_data}
conn <- dbConnect(noctua::athena(), rstudio_conn_tab = FALSE)

cache_dir <- "data/assessment_card"
dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE)

cache_file <- file.path(cache_dir, "assessment_card.parquet")

if (!file.exists(cache_file)) {
  message("Cache not found. Querying Athena and saving to cache...")

  assessment_card <- dbGetQuery(
    conn,
    "SELECT * FROM pinval.vw_assessment_card"
  )

  write_parquet(assessment_card, cache_file)
} else {
  message("Reading cached file")
  assessment_card <- read_parquet(cache_file)
}
```

```{r download_logs}
log_group_name <- "/aws-cloudfront/pinval-prod"
log_stream_name <- "CloudFront_E3AIN3GTEPCCYR"

out_dir <- fs::path_abs("data/cloudwatch_cache")
fs::dir_create(out_dir)
message("Writing to: ", out_dir)

cloudwatchlogs_client <- paws::cloudwatchlogs()

to_epoch_ms_utc <- function(x_dt_local) {
  as.numeric(with_tz(x_dt_local, "UTC")) * 1000
}

fetch_events_for_day <- function(date_local) {
  # Dates are queried in epoch time and converted to local
  # time to make data readable
  start_local <- as.POSIXct(date_local, tz = tz_local)
  end_local <- start_local + days(1)

  start_ms <- to_epoch_ms_utc(start_local)
  end_ms <- to_epoch_ms_utc(end_local)

  # Create an initial call
  resp <- cloudwatchlogs_client$get_log_events(
    logGroupName  = log_group_name,
    logStreamName = log_stream_name,
    startTime     = start_ms,
    endTime       = end_ms,
    startFromHead = TRUE
  )

  events <- resp$events %||% list()
  prev_token <- NULL
  next_token <- resp$nextForwardToken %||% NULL

  # Keep calling until token stops changing
  while (!is.null(next_token) && !identical(next_token, prev_token)) {
    prev_token <- next_token
    resp <- cloudwatchlogs_client$get_log_events(
      logGroupName      = log_group_name,
      logStreamName     = log_stream_name,
      endTime           = end_ms,
      nextToken         = next_token,
      startFromHead     = TRUE
    )
    events <- c(events, resp$events %||% list())
    next_token <- resp$nextForwardToken %||% NULL
  }

  if (length(events) == 0) {
    return(tibble(
      timestamp = numeric(0),
      message   = character(0),
      datetime  = as.POSIXct(character(0)),
      date      = as.Date(character(0))
    ))
  }

  tibble(
    timestamp = map_dbl(events, ~ .x$timestamp),
    message   = map_chr(events, ~ .x$message)
  ) %>%
    mutate(
      # CloudWatch timestamps are epoch ms in UTC
      datetime = with_tz(as_datetime(timestamp / 1000, tz = "UTC"), tz_local),
      date     = as.Date(datetime)
    )
}

# Look for already-cached files like logs_YYYY-MM-DD.parquet
cached_files <- dir_ls(out_dir,
  regexp = "logs_\\d{4}-\\d{2}-\\d{2}\\.parquet$",
  type = "file"
)
# Match dates in cached filenames
cached_dates <- str_match(
  basename(cached_files),
  "logs_(\\d{4}-\\d{2}-\\d{2})\\.parquet"
)[, 2]

cached_dates <- as.Date(na.omit(cached_dates))

# Build the full sequence of dates
all_dates <- seq(start_date, end_date, by = "day")

# Remove days which should be excluded via the params.
dates_to_fetch <- c(
  setdiff(
    all_dates[
      (all_dates != end_date) |
        (is.null(params$refresh_today) || isTRUE(params$refresh_today))
    ],
    c(
      cached_dates,
      if (!is.null(params$excluded_dates)) {
        as.Date(params$excluded_dates)
      }
    )
  ),
  if (is.null(params$refresh_today) ||
    isTRUE(params$refresh_today)) { # nolint
    end_date
  } else {
    NULL
  }
) |> sort()



message(
  "Dates to fetch (", length(dates_to_fetch), "): ",
  paste(format(dates_to_fetch), collapse = ", ")
)

walk(dates_to_fetch, function(d) {
  out_file <- fs::path(out_dir, paste0("logs_", format(d), ".parquet"))
  message("Target file: ", fs::path_abs(out_file))

  if (fs::file_exists(out_file) & d != end_date) {
    message("Skipping ", format(d), " (already cached).")
    return(invisible(NULL))
  }

  message("Fetching ", format(d), " ...")
  df <- fetch_events_for_day(d)

  arrow::write_parquet(df, out_file)
  message("Wrote ", nrow(df), " events to ", fs::path_abs(out_file))
  stopifnot(fs::file_exists(out_file))
  message("Verified exists: ", as.character(fs::file_size(out_file)), " bytes")
})

# List all log files
logs <- fs::dir_ls(
  out_dir,
  regexp = "logs_\\d{4}-\\d{2}-\\d{2}\\.parquet$",
  type   = "file"
)

# Extract date from filenames
log_dates <- stringr::str_extract(basename(logs), "\\d{4}-\\d{2}-\\d{2}") %>%
  as.Date()

# Filter imports based on params
logs_to_import <- tibble(file = logs, date = log_dates) %>%
  dplyr::filter(
    # End date filter
    if (!is.null(params$end_date) &
      nzchar(params$end_date)) { # nolint
      date <= as.Date(params$end_date)
    } else {
      TRUE
    },

    # Start date filter
    if (!is.null(params$start_date) &
      nzchar(params$start_date)) { # nolint
      date >= as.Date(params$start_date)
    } else {
      TRUE
    },

    # Excluded dates filter
    if (!is.null(params$excluded_dates) &
      length(params$excluded_dates) > 0) { # nolint
      !(date %in% as.Date(params$excluded_dates))
    } else {
      TRUE
    }
  )

# Read only selected files
logs <- purrr::map_dfr(logs_to_import$file, arrow::read_parquet)
```


```{r parse_data}
fields <- c(
  "date", "time", "sc-bytes", "c-ip", "cs-method", "cs(Host)",
  "cs-uri-stem", "sc-status", "cs(Referer)", "cs(User-Agent)",
  "cs-uri-query", "x-host-header", "cs-protocol", "cs-bytes",
  "time-taken", "x-forwarded-for", "x-edge-response-result-type",
  "cs-protocol-version", "c-port", "time-to-first-byte",
  "sc-content-type", "sc-content-len"
)

data <- logs %>%
  mutate(parsed = purrr::map(message, ~ {
    val <- jsonlite::fromJSON(.x, simplifyVector = TRUE)
    out <- setNames(vector("list", length(fields)), fields)
    for (nm in fields) {
      out[[nm]] <-
        if (nm %in% names(val)) as.character(val[[nm]]) else NA_character_
    }
    out
  })) %>%
  select(-any_of(fields)) %>%
  tidyr::unnest_wider(parsed, names_repair = "minimal") %>%
  filter(
    # excluded IPs
    if (!is.null(params$ip_addresses_to_filter) &
      length(params$ip_addresses_to_filter) > 0) { # nolint
      !(`c-ip` %in% params$ip_addresses_to_filter)
    } else {
      TRUE
    }
  ) %>%
  mutate(
    pin = coalesce(
      str_extract(`cs-uri-stem`, "(?<=/)\\d{14}"),
      str_extract(`cs(Referer)`, "\\d{14}(?=\\.html)")
    ),
    extract_year = coalesce(
      str_extract(`cs-uri-stem`, "(?<=/)(202[0-9])(?=/)"),
      str_extract(`cs(Referer)`, "(?<=/)(202[0-9])(?=/)")
    ),
    extract_year = as.integer(extract_year),
    # This is an indicator for the main query, or the query
    # for the static assets.
    # For the rest of the document, we will use the value of 'Query'
    # when trying to identify a unique query. We keep the static in
    # to see how many static assets are hit and we keep in Other
    # to look for bot requests.
    uri_indicator = case_when(
      str_detect(`cs-uri-stem`, "^/202[0-9]/") ~ "Query",
      str_detect(`cs-uri-stem`, "^/static/") ~ "Static",
      TRUE ~ "Other"
    ),
  ) %>%
  left_join(
    assessment_card %>%
      mutate(assessment_year = as.integer(assessment_year)) %>%
      select(
        meta_pin, char_class, assessment_year,
        meta_triad_name, meta_card_num, is_report_eligible,
        reason_report_ineligible, meta_township_name, loc_latitude,
        loc_longitude
      ),
    by = c("pin" = "meta_pin", "extract_year" = "assessment_year")
  )
```

---

## Request Count by Class

NA values are for PINs which do not have a matching assessment_card record.

::: {.panel-tabset}

### Overall


```{r class_overall}
# We want to keep multi-cards just for the class related plots
data_class <- data %>%
  filter(uri_indicator == "Query") %>%
  mutate(
    # Make sure we identify PINs which are incorrect
    # or not joined to assessment_card
    # For example PIN 14110010074923
    char_class = if_else(is.na(char_class), "NA", as.character(char_class))
  ) %>%
  # This keeps unique classes by queries.
  # If a multi-class card is queried, it will return
  # one value for the class tables.
  # Datetime has issues with second lag, so it is not
  # a fool-proof method.
  distinct(pin, date, datetime, char_class)

data_class %>%
  group_by(char_class) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  plot_ly(
    x = ~char_class,
    y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = paste(
      "Class: %{x}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    xaxis = list(title = "Class"),
    yaxis = list(title = "Count"),
    showlegend = FALSE
  )
```


### Count Over Time

```{r class_time}
data_class %>%
  group_by(date, char_class) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  plot_ly(
    x = ~date,
    y = ~request_count,
    color = ~char_class,
    type = "bar",
    hovertemplate = paste(
      "Date: %{x}<br>",
      "Class: %{fullData.name}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    barmode = "stack",
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Count"),
    legend = list(title = list(text = "Class"))
  )
```

### % Over Time

```{r class_percent_time}
data_class %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date, char_class) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  group_by(date) %>%
  mutate(pct = request_count / sum(request_count) * 100) %>%
  plot_ly(
    x = ~date,
    y = ~pct,
    color = ~char_class,
    type = "bar",
    hovertemplate = paste(
      "Date: %{x}<br>",
      "Class: %{fullData.name}<br>",
      "Share: %{y:.1f}%<extra></extra>"
    )
  ) %>%
  layout(
    barmode = "stack",
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Percentage", ticksuffix = "%"),
    legend = list(title = list(text = "Class"))
  )
```
:::

---

## Request Count by Extract Year

Extract year refers to the year which the user queried the data for.

::: {.panel-tabset}

### Overall

```{r count_by_year}
# This removes the duplicate cards from the previous join.
data <- data %>%
  distinct(message, .keep_all = TRUE) %>%
  mutate(extract_year = as.character(extract_year))

data %>%
  group_by(extract_year) %>%
  filter(uri_indicator == "Query") %>%
  summarise(request_count = n(), .groups = "drop") %>%
  plot_ly(
    x = ~extract_year,
    y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = paste(
      "Year: %{x}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    xaxis = list(title = "Year"),
    yaxis = list(title = "Count")
  )
```

### Total Over Time

```{r count_over_time}
data %>%
  filter(
    uri_indicator == "Query"
  ) %>%
  group_by(date, extract_year) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  plot_ly(
    x = ~date,
    y = ~request_count,
    color = ~extract_year,
    type = "bar",
    hovertemplate = paste(
      "Date: %{x}<br>",
      "Year: %{fullData.name}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    barmode = "stack",
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Count"),
    legend = list(title = list(text = "Year"))
  )
```

### % Over Time

```{r percent_over_time}
data %>%
  filter(
    uri_indicator == "Query"
  ) %>%
  group_by(date, extract_year) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  group_by(date) %>%
  mutate(pct = request_count / sum(request_count) * 100) %>%
  plot_ly(
    x = ~date,
    y = ~pct,
    color = ~extract_year,
    type = "bar",
    hovertemplate = paste(
      "Date: %{x}<br>",
      "Year: %{fullData.name}<br>",
      "Share: %{y:.1f}%<extra></extra>"
    )
  ) %>%
  layout(
    barmode = "stack",
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Percentage", ticksuffix = "%"),
    legend = list(title = list(text = "Year"))
  )
```

:::

---

## Request Count by Report Eligibility

::: {.panel-tabset}

### Overall

```{r eligibility_overall}
data %>%
  filter(uri_indicator == "Query") %>%
  mutate(
    eligibility = case_when(
      is_report_eligible == TRUE ~ "Eligible",
      is_report_eligible == FALSE ~ "Not Eligible",
      is.na(is_report_eligible) ~ "N/A"
    )
  ) %>%
  count(eligibility, name = "request_count") %>%
  plot_ly(
    x = ~eligibility,
    y = ~request_count,
    type = "bar",
    marker = list(color = c("lightblue", "tomato", "grey")),
    hovertemplate = paste(
      "Eligibility: %{x}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    xaxis = list(title = "Eligibility"),
    yaxis = list(title = "Count")
  )
```

### Type of Ineligibility Reason

This allows for duplicate reasons if the same query is deemed ineligible.

```{r eligibility_reasons}
ineligbility_data <- data %>%
  filter(
    uri_indicator == "Query",
    # This filters out eligible pins which will all have NA reason
    # It allow us to keep queries which did not have a valid pin
    # as their own category and provide an Invalid PIN reason.
    is_report_eligible %in% c(FALSE, NA)
  ) %>%
  mutate(
    reason_clean = case_when(
      is.na(reason_report_ineligible) ~ "Invalid PIN",
      TRUE ~ as.character(reason_report_ineligible)
    )
  )

ineligbility_data %>%
  count(reason_clean, name = "request_count") %>%
  plot_ly(
    x = ~reason_clean,
    y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = paste(
      "Reason: %{x}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    xaxis = list(
      title = "Eligibility Reason",
      categoryorder = "total descending"
    ),
    yaxis = list(title = "Count")
  )
```

### Count Over Time

```{r eligibility_time}
ineligbility_data %>%
  count(reason_clean, date, name = "request_count") %>%
  plot_ly(
    x = ~date,
    y = ~request_count,
    color = ~reason_clean,
    type = "bar",
    hovertemplate = paste(
      "Date: %{x}<br>",
      "Reason: %{fullData.name}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    barmode = "stack",
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Count"),
    legend = list(title = list(text = "Eligibility Reason"))
  )
```

### % Over Time

```{r eligibility_percent_time}
ineligbility_data %>%
  count(date, reason_report_ineligible, name = "request_count") %>%
  complete(date, reason_report_ineligible, fill = list(request_count = 0)) %>%
  group_by(date) %>%
  mutate(pct = 100 * request_count / sum(request_count)) %>%
  ungroup() %>%
  arrange(date) %>%
  plot_ly(
    x = ~date,
    y = ~pct,
    color = ~reason_report_ineligible,
    type = "bar",
    hovertemplate = "Date: %{x}<br>Reason:
    %{fullData.name}<br>Share: %{y:.1f}%<extra></extra>"
  ) %>%
  layout(
    barmode = "stack",
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Percentage", ticksuffix = "%"),
    legend = list(title = list(text = "Eligibility Reason"))
  )
```
:::

---

```{r prepare_township_year}
df_counts <- data %>%
  filter(uri_indicator == "Query") %>%
  mutate(
    township = dplyr::coalesce(meta_township_name, "NA"),
    triad = dplyr::coalesce(meta_triad_name, "NA"),
    extract_year = dplyr::coalesce(extract_year, "NA")
  ) %>%
  group_by(extract_year, triad, township) %>%
  summarise(request_count = n(), .groups = "drop")

plot_township_year <- function(df_counts, target_year) {
  df_y <- df_counts %>%
    filter(extract_year == target_year) %>%
    mutate(x_label = paste(triad, township, sep = " | ")) %>%
    arrange(triad, township)

  plot_ly(
    df_y,
    x = ~x_label,
    y = ~request_count,
    type = "bar",
    color = ~triad,
    hovertemplate = paste(
      "Year: ", target_year, "<br>",
      "Township: %{x}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
    layout(
      xaxis = list(title = "Triad | Township"),
      yaxis = list(title = "Count"),
      legend = list(title = list(text = "Triad"))
    )
}

years <- sort(unique(df_counts$extract_year))
```

## Request Count by Township and Query Year

::: {.panel-tabset}

### Overall

```{r township_overall}
data %>%
  filter(uri_indicator == "Query") %>%
  transmute(
    triad    = dplyr::coalesce(meta_triad_name, "NA"),
    township = dplyr::coalesce(meta_township_name, "NA")
  ) %>%
  count(triad, township, name = "request_count") %>%
  arrange(triad, township) %>%
  mutate(x_label = paste(triad, township, sep = " | ")) %>%
  plot_ly(
    x = ~x_label,
    y = ~request_count,
    type = "bar",
    color = ~triad,
    hovertemplate = paste(
      "Triad | Township: %{x}<br>",
      "Count: %{y}<extra></extra>"
    )
  ) %>%
  layout(
    xaxis = list(title = "Triad | Township"),
    yaxis = list(title = "Count"),
    legend = list(title = list(text = "Triad"))
  )
```


### 2024
```{r 2024}
plot_township_year(df_counts, "2024")
```

### 2025

```{r 2025}
plot_township_year(df_counts, "2025")
```
:::

---

## Map of Distinct Queried Pins

This map filters out any queries for PINs that do not have coordinates in the
underlying data, which is always true for non-tri PINs. As such, any queries
for non-tri PINs (e.g. north suburbs PINs in 2024) will not appear on this map.

```{r map_distinct_pins}
df <- data %>%
  filter(uri_indicator == "Query") %>%
  distinct(pin, .keep_all = TRUE) %>%
  filter(!is.na(loc_latitude), !is.na(loc_longitude)) %>%
  mutate(
    extract_year = as.factor(extract_year)
  )

pal <- colorFactor(
  palette = "Set1",
  domain = df$extract_year,
  na.color = "gray"
)


leaflet(df) %>%
  addProviderTiles("OpenStreetMap") %>%
  addCircleMarkers(
    lng = ~loc_longitude,
    lat = ~loc_latitude,
    radius = 4,
    color = ~ pal(extract_year),
    stroke = FALSE,
    fillOpacity = 0.7
  ) %>%
  addLegend(
    "bottomright",
    pal = pal,
    values = ~extract_year,
    title = "Extract Year",
    opacity = 1
  )
```

## Distribution of HTTP Response Status Code over Time

::: {.panel-tabset}

### Excluding Static File Requests

```{r http_status_excluding_static}
data %>%
  mutate(
    date   = as.Date(datetime),
    status = ifelse(is.na(`sc-status`), "Unknown", as.character(`sc-status`))
  ) %>%
  filter(uri_indicator == "Query") %>%
  count(date, status, name = "Count") %>%
  arrange(date, status) %>%
  plot_ly(
    x = ~date,
    y = ~Count,
    color = ~status,
    type = "scatter",
    mode = "lines+markers",
    hovertemplate = "Date: %{x}<br>Status:
    %{fullData.name}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Count"),
    legend = list(title = list(text = "Status"))
  )
```

### Including Static File Requests

```{r http_status_including_static}
data %>%
  mutate(
    date   = as.Date(datetime),
    status = ifelse(is.na(`sc-status`), "Unknown", as.character(`sc-status`))
  ) %>%
  count(date, status, name = "Count") %>%
  arrange(date, status) %>%
  plot_ly(
    x = ~date,
    y = ~Count,
    color = ~status,
    type = "scatter",
    mode = "lines+markers",
    hovertemplate = "Date: %{x}<br>Status:
    %{fullData.name}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Count"),
    legend = list(title = list(text = "Status"))
  )
```

### Recent Errors (non-2xx/3xx status codes)

```{r recent_errors}
data %>%
  # Keep only errors (not 2xx or 3xx)
  filter(!is.na(`sc-status`), !substr(`sc-status`, 1, 1) %in% c("2", "3")) %>%
  mutate(
    timestamp = as.POSIXct(datetime),
    status    = as.character(`sc-status`),
    path      = `cs-uri-stem`
  ) %>%
  arrange(desc(timestamp)) %>%
  slice_head(n = 100) %>%
  plot_ly(
    type = "table",
    header = list(
      values = c("Timestamp", "Status", "Path"),
      fill = list(color = "lightgrey"),
      align = "left"
    ),
    cells = list(
      values = list(~timestamp, ~status, ~path),
      align = "left"
    )
  )
```

:::

## Most Common Browsers

::: {.panel-tabset}

### Excluding Static File Requests

```{r common_browsers_excluding_static}
normalize_browser <- function(x) {
  x <- str_to_lower(str_squish(x))
  case_when(
    str_detect(x, "chrome") ~ "Chrome",
    str_detect(x, "edge") ~ "Edge",
    str_detect(x, "firefox") ~ "Firefox",
    str_detect(x, "opera") ~ "Opera",
    str_detect(x, "safari") ~ "Safari",
    str_detect(x, "samsung") ~ "Samsung",
    str_detect(x, "internet explorer") ~ "Internet Explorer",
    str_detect(x, "whatsapp") ~ "WhatsApp",
    str_detect(x, "facebook") ~ "Facebook",
    str_detect(x, "slack") ~ "Slack",
    str_detect(x, "linkedin") ~ "LinkedIn",
    str_detect(x, "apple") ~ "Apple",
    TRUE ~ str_to_title(x)
  )
}

data %>%
  mutate(parsed = ua_parse(`cs(User-Agent)`)) %>%
  filter(uri_indicator == "Query") %>%
  unnest_wider(parsed) %>%
  rename(browser = `ua.family`) %>%
  mutate(browser = normalize_browser(browser)) %>%
  count(browser, name = "request_count") %>%
  mutate(browser = fct_reorder(browser, request_count)) %>%
  plot_ly(
    x = ~browser, y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = "Browser: %{x}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(title = "Browser"),
    yaxis = list(title = "Count")
  )
```

### Including Static File Requests

```{r common_browsers_including_static}
data %>%
  mutate(parsed = ua_parse(`cs(User-Agent)`)) %>%
  unnest_wider(parsed) %>%
  rename(browser = `ua.family`) %>%
  mutate(browser = normalize_browser(browser)) %>%
  count(browser, name = "request_count") %>%
  mutate(browser = fct_reorder(browser, request_count)) %>%
  plot_ly(
    x = ~browser, y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = "Browser: %{x}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(title = "Browser"),
    yaxis = list(title = "Count")
  )
```


---

:::

## Most Common Referer Domains

::: {.panel-tabset}

### Excluding Static File Requests

```{r common_referer_excluding_static}
data %>%
  filter(uri_indicator == "Query") %>%
  mutate(
    referer_raw = `cs(Referer)`,
    domain = ifelse(
      is.na(referer_raw) | referer_raw == "-",
      "None",
      domain(referer_raw)
    )
  ) %>%
  group_by(domain) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  arrange(desc(request_count)) %>%
  plot_ly(
    x = ~ reorder(domain, request_count),
    y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = "Domain: %{x}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(title = "Domain"),
    yaxis = list(title = "Count"),
    bargap = 0.2
  )
```

### Including Static File Requests

```{r common_referer_including_static}
data %>%
  mutate(
    referer_raw = `cs(Referer)`,
    domain = ifelse(
      is.na(referer_raw) | referer_raw == "-",
      "None",
      domain(referer_raw)
    )
  ) %>%
  group_by(domain) %>%
  summarise(request_count = n(), .groups = "drop") %>%
  arrange(desc(request_count)) %>%
  plot_ly(
    x = ~ reorder(domain, request_count),
    y = ~request_count,
    type = "bar",
    marker = list(color = "lightblue"),
    hovertemplate = "Domain: %{x}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(title = "Domain"),
    yaxis = list(title = "Count"),
    bargap = 0.2
  )
```


---

:::

## Cache Hit Rate over Time

::: {.panel-tabset}

### Excluding Static File Requests

```{r cache_hit_excluding_static}
data %>%
  filter(uri_indicator == "Query") %>%
  mutate(
    result_type = as.character(`x-edge-response-result-type`),
    is_hit = str_detect(
      coalesce(result_type, ""),
      regex("hit|redirect", ignore_case = TRUE)
    )
  ) %>%
  group_by(date) %>%
  summarise(
    count = n(),
    cache_hit_pct = 100 * sum(is_hit, na.rm = TRUE) / count,
    .groups = "drop"
  ) %>%
  arrange(date) %>%
  plot_ly(
    x = ~date,
    y = ~cache_hit_pct,
    type = "scatter",
    mode = "lines+markers",
    hovertemplate = "Date: %{x}<br>Cache hit: %{y:.1f}%<extra></extra>"
  ) %>%
  layout(
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Cache hit %", ticksuffix = "%")
  )
```

### Including Static File Requests

```{r cache_hit_including_static}
data %>%
  mutate(
    result_type = as.character(`x-edge-response-result-type`),
    is_hit = str_detect(
      coalesce(result_type, ""),
      regex("hit|redirect", ignore_case = TRUE)
    )
  ) %>%
  group_by(date) %>%
  summarise(
    count = n(),
    cache_hit_pct = 100 * sum(is_hit, na.rm = TRUE) / count,
    .groups = "drop"
  ) %>%
  arrange(date) %>%
  plot_ly(
    x = ~date,
    y = ~cache_hit_pct,
    type = "scatter",
    mode = "lines+markers",
    hovertemplate = "Date: %{x}<br>Cache hit: %{y:.1f}%<extra></extra>"
  ) %>%
  layout(
    xaxis = list(
      title = "Date",
      nticks = 10,
      tickformat = "%b %d",
      automargin = TRUE,
      tickangle = 45
    ),
    yaxis = list(title = "Cache hit %", ticksuffix = "%")
  )
```

:::

## Request Times

::: {.panel-tabset}

### Time to First byte

```{r time_to_first_byte}
data %>%
  filter(uri_indicator != "Other") %>%
  mutate(
    time_to_first_byte_ms = as.numeric(`time-to-first-byte`) * 1000
  ) %>%
  plot_ly(
    x = ~time_to_first_byte_ms,
    type = "histogram",
    nbinsx = 50,
    marker = list(color = "lightblue"),
    hovertemplate =
      "Time to first byte (ms):%{x}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(title = "Time to First Byte (ms)"),
    yaxis = list(title = "Count")
  )
```

### Time Taken

```{r time_taken}
data %>%
  filter(uri_indicator != "Other") %>%
  mutate(
    time_taken_ms = as.numeric(`time-taken`) * 1000
  ) %>%
  plot_ly(
    x = ~time_taken_ms,
    type = "histogram",
    nbinsx = 50,
    marker = list(color = "lightblue"),
    hovertemplate = "Time taken (ms): %{x}<br>Count: %{y}<extra></extra>"
  ) %>%
  layout(
    xaxis = list(title = "Time Taken (ms)"),
    yaxis = list(title = "Count")
  )
```

:::
