---
title: "Algorithm-Comparison"
format: html
params:
  year: 2025
  run_id:
    - "2025-10-18-blissful-sean"
    - "2025-06-14-flamboyant-rob"
    - "2025-04-25-fancy-free-billy"
    - "2025-03-26-vibrant-bowen"
    - "2025-09-20-fervent-bowen"
  description:
    - "Unweighted"
    - "Unweighted (error-reducing trees only)"
    - "Error reduction"
    - "Error reduction (semi-random)"
    - "Prediction variance"
---

```{r load_data}
library(arrow)
library(ccao)
library(data.table)
library(dtplyr)
library(DT)
library(glue)
library(gt)
library(matrixStats)
library(noctua)
library(plotly)
library(readxl)
library(sf)
library(tidyverse)
```


```{r load_data}
year <- params$year
n_years_sales <- 3
keep_top_n_comps <- 5 # How many comps to keep
total_n_comps <- 5 # The total number of comps to analyze
triad <- "1" # Which tri to filter comps for; should match the run ID

s3_bucket <- "s3://ccao-model-results-us-east-1"
year <- params$year
run_ids <- params$run_id

year <- params$year
s3_bucket <- "s3://ccao-model-results-us-east-1"

run_tbl <- tibble::tibble(
  run_id = params$run_id,
  description = params$description
)

data <- pmap(
  .l = list(run_id = run_tbl$run_id, description = run_tbl$description),
  .f = function(run_id, description) {
    message("Processing run_id: ", run_id, " (", description, ")")

    comps <- read_parquet(glue(
      "{s3_bucket}/comp/year={year}/run_id={run_id}/part-0.parquet"
    )) %>%
      mutate(year = !!year, run_id = !!run_id, description = !!description,
             .before = 1)

    preds_pin <- collect(open_dataset(glue(
      "{s3_bucket}/assessment_pin/year={year}/run_id={run_id}/"
    ))) %>%
      mutate(year = !!year, run_id = !!run_id, description = !!description,
             .before = 1)

    preds_card <- collect(open_dataset(glue(
      "{s3_bucket}/assessment_card/year={year}/run_id={run_id}/"
    ))) %>%
      mutate(year = !!year, run_id = !!run_id, description = !!description,
             .before = 1)

    dvc_md5_hash <- read_parquet(
      glue("{s3_bucket}/metadata/year={year}/{run_id}.parquet")
    ) %>%
      pull(dvc_md5_training_data)

    training_data_prefix <- substr(dvc_md5_hash, 1, 2)
    training_data_filename <- substr(dvc_md5_hash, 3, nchar(dvc_md5_hash))

    training_data <- read_parquet(glue(
      "s3://ccao-data-dvc-us-east-1/files/md5/{training_data_prefix}/{training_data_filename}"
    )) %>%
      mutate(year = !!year, run_id = !!run_id, description = !!description,
             .before = 1)

    list(
      comps = comps,
      preds_pin = preds_pin,
      preds_card = preds_card,
      training_data = training_data
    )
  }
)

comps <- map(data, "comps") %>%
  bind_rows()
preds_pin     <- map(data, "preds_pin") %>%
  bind_rows()
preds_card    <- map(data, "preds_card") %>%
  bind_rows()
training_data <- map(data, "training_data") %>%
  bind_rows()

rm(data)

noctua_options(unload = TRUE)
conn <- dbConnect(noctua::athena(), rstudio_conn_tab = FALSE)

# Helper function to generate a SQL statement that applies an aggregation
# function `agg_fun` to the log of a column `charname`.
# We want to log some of our features before computing Z scores because their
# distributions are not normal.
# Be sure to handle zero or negative values when taking the log of columns
# by setting a `floor`, since otherwise the return value will be undefined
agg_log_char_sql <- function(agg_fun, charname, floor) {
  return(
    glue(
      "{agg_fun}(
        ln(case when {charname} <= 0 then {floor} else {charname} end)
      ) as agg_{agg_fun}_log_{sub('^char_', '', charname)}"
    )
  )
}

# Load aggregate char stats via Athena query, so that we don't have to pull all
# of the data into memory
agg_char_stats <- dbGetQuery(
  conn,
  # Make sure to log all sqft features, since they aren't normally distributed.
  # Beds and baths are also not normally distributed but they're difficult to
  # normalize since 0 is an important value to preserve
  glue("
  select
    year,
    avg(cast(char_yrblt as double)) as agg_avg_yrblt,
    {agg_log_char_sql('avg', 'char_bldg_sf', floor = 1)},
    {agg_log_char_sql('avg', 'char_land_sf', floor = 1)},
    avg(cast(char_beds as double)) as agg_avg_beds,
    avg(cast(char_fbath as double)) as agg_avg_fbath,
    avg(cast(char_hbath as double)) as agg_avg_hbath,
    stddev(cast(char_yrblt as double)) as agg_stddev_yrblt,
    {agg_log_char_sql('stddev', 'char_bldg_sf', floor = 1)},
    {agg_log_char_sql('stddev', 'char_land_sf', floor = 1)},
    stddev(cast(char_beds as double)) as agg_stddev_beds,
    stddev(cast(char_fbath as double)) as agg_stddev_fbath,
    stddev(cast(char_hbath as double)) as agg_stddev_hbath
  from default.vw_card_res_char
  group by year order by year
  ")
)
```

```{r top_char_z_scores}
# Calculate zscores for top chars in training and assessment sets, so that we
# can compute char distance metrics
training_data <- training_data %>%
    left_join(agg_char_stats, by = c("meta_year" = "year")) %>%
    mutate(
      across(
        starts_with("char_") & ends_with("_sf"),
        ~ pmax(.x, 1),
        .names = "{.col}_safe"
      ),
      z_yrblt  = (char_yrblt - agg_avg_yrblt) / agg_stddev_yrblt,
      z_bldg_sf = (log(char_bldg_sf_safe) - agg_avg_log_bldg_sf) / agg_stddev_log_bldg_sf,
      z_land_sf = (log(char_land_sf_safe) - agg_avg_log_land_sf) / agg_stddev_log_land_sf,
      z_beds   = (char_beds - agg_avg_beds) / agg_stddev_beds,
      z_hbath  = (char_hbath - agg_avg_hbath) / agg_stddev_hbath,
      z_fbath  = (char_fbath - agg_avg_fbath) / agg_stddev_fbath
    ) %>%
    select(-ends_with("_safe"))

training_data <- training_data %>%
  group_by(run_id) %>%
    mutate(
      across(
        starts_with("char_") & ends_with("_sf"),
        ~ pmax(.x, 1),
        .names = "{.col}_safe"
      ),
      z_yrblt  = (char_yrblt - agg_avg_yrblt) / agg_stddev_yrblt,
      z_bldg_sf = (log(char_bldg_sf_safe) - agg_avg_log_bldg_sf) / agg_stddev_log_bldg_sf,
      z_land_sf = (log(char_land_sf_safe) - agg_avg_log_land_sf) / agg_stddev_log_land_sf,
      z_beds   = (char_beds - agg_avg_beds) / agg_stddev_beds,
      z_hbath  = (char_hbath - agg_avg_hbath) / agg_stddev_hbath,
      z_fbath  = (char_fbath - agg_avg_fbath) / agg_stddev_fbath
    ) %>%
    select(-ends_with("_safe"))
```

```{r clean_data}
# Convert the wide comps data (2 columns per comp, score and PIN) to a long
# format, with N rows of comps for each PIN. We want to do this with a few
# different types of comp columns, so abstract out the logic using a
# `starts_with` param that determines the pattern for columns to pivot
pivot_comps_longer <- function(comps, starts_with_text) {
  return(
    comps %>%
      select(pin, card, starts_with(glue(starts_with_text, "_"))) %>%
      pivot_longer(
        cols = starts_with(starts_with_text),
        names_to = "comp_num",
        values_to = starts_with_text
      ) %>%
      mutate(comp_num = as.integer(str_extract(comp_num, "\\d+")))
  )
}
comps_pin_long <- comps %>%
  group_by(run_id) %>%
  group_modify(~ pivot_comps_longer(.x, "comp_pin")) %>%
  ungroup()

comps_score_long <- comps %>%
  group_by(run_id) %>%
  group_modify(~ pivot_comps_longer(.x, "comp_score")) %>%
  ungroup()

comps_doc_no_long <- comps %>%
  group_by(run_id) %>%
  group_modify(~ pivot_comps_longer(.x, "comp_document_num")) %>%
  ungroup()

comps_long <- comps_pin_long %>%
  left_join(comps_score_long,
            by = c("run_id", "pin", "card", "comp_num")) %>%
  left_join(comps_doc_no_long,
            by = c("run_id", "pin", "card", "comp_num")) %>%
  rename(target_pin = pin, target_card = card)

# -- Build card_locs for every run_id -----------------------------------------
card_locs <- preds_card %>%
  select(run_id, meta_pin, meta_card_num, loc_latitude, loc_longitude) %>%
  filter(!is.na(loc_latitude), !is.na(loc_longitude)) %>%
  group_by(run_id) %>%
  group_modify(~ .x %>%
                 st_as_sf(coords = c("loc_longitude", "loc_latitude"), crs = 4326) %>%
                 st_transform(3435)) %>%
  ungroup() %>%
  rename(target_geometry = geometry)

# -- Merge comps_long to card_locs by run_id + target ids ----------------------
merged_model_comps <- comps_long %>%
  left_join(card_locs,
            by = c("run_id",
                   "target_pin"  = "meta_pin",
                   "target_card" = "meta_card_num"))

# Get PIN geometries from the centroids in the cards data, which is used as
# the set of "targets" for comps
card_locs <- preds_card %>%
    select(meta_pin, meta_card_num, loc_latitude, loc_longitude) %>%
    filter(!is.na(loc_latitude), !is.na(loc_longitude)) %>%
    st_as_sf(coords = c("loc_longitude", "loc_latitude"), crs = 4326) %>%
    st_transform(3435) %>%
    rename(target_geometry = geometry)


# Load the sales used to train the model (the source of the comps). Using the
# same subsetting logic as the model/comps algo to ensure the same sales data
# is used
training_data_clean <- training_data %>%
  filter(!ind_pin_is_multicard, !sv_is_outlier) %>%
  select(
    meta_pin, meta_card_num, run_id, description,
    meta_sale_document_num, meta_sale_price, meta_sale_date,
    char_yrblt, z_yrblt, agg_avg_yrblt, agg_stddev_yrblt,
    char_bldg_sf, z_bldg_sf, agg_avg_log_bldg_sf, agg_stddev_log_bldg_sf,
    char_land_sf, z_land_sf, agg_avg_log_land_sf, agg_stddev_log_land_sf,
    char_beds, z_beds, agg_avg_beds, agg_stddev_beds,
    char_fbath, z_fbath, agg_avg_fbath, agg_stddev_fbath,
    char_hbath, z_hbath, agg_avg_hbath, agg_stddev_hbath,
    loc_latitude, loc_longitude
  )

# Get the PIN geometries (centroids) for the training data, which is used to
# determine the price/location of each comp sale
training_data_clean_geo <- training_data_clean %>%
  filter(!is.na(loc_latitude)) %>%
  st_as_sf(coords = c("loc_longitude", "loc_latitude"), crs = 4326) %>%
  st_transform(3435)

training_data_clean_no_geo <- training_data_clean %>%
  filter(is.na(loc_latitude))

training_data_clean <- bind_rows(
  training_data_clean_geo,
  training_data_clean_no_geo
)

# Merge comps, predictions, and target sale prices into a single working dataset
merged_model_comps <- comps_long %>%
  # Merge target locations
  left_join(
    card_locs,
    by = c("target_pin" = "meta_pin", "target_card" = "meta_card_num")
  ) %>%
  # Merge target chars
  left_join(
    preds_card %>%
      select(
        meta_pin,
        meta_card_num,
        target_township_code = meta_township_code,
        target_nbhd_code = meta_nbhd_code,
        target_class = meta_class,
        target_pred_card_initial_fmv = pred_card_initial_fmv,
        target_char_yrblt = char_yrblt,
        target_char_bldg_sf = char_bldg_sf,
        target_char_land_sf = char_land_sf,
        target_char_beds = char_beds,
        target_char_fbath = char_fbath,
        target_char_hbath = char_hbath,
        starts_with("target_")
      ),
    by = c("target_pin" = "meta_pin", "target_card" = "meta_card_num")
  ) %>%
  # Merge target sale price. To do this, we join to any recent sales for the
  # target. Note that this means a many-to-many join, and can create dupes
  # for targets that have sold multiple times in the last n_years_sales
  left_join(
    training_data_clean %>%
      filter(year(meta_sale_date) >= year(max(meta_sale_date)) + 1 - n_years_sales) %>%
      select(
        meta_pin, meta_card_num,
        target_sale_document_num = meta_sale_document_num,
        target_sale_price = meta_sale_price,
        target_sale_date = meta_sale_date,
      ) %>%
      st_drop_geometry(),
    by = c("target_pin" = "meta_pin", "target_card" = "meta_card_num"),
    relationship = "many-to-many"
  ) %>%
  # Merge comp chars
  left_join(
    training_data_clean %>%
      # Convert training data from simple feature collection to dataframe so we
      # can join it to the rest of the data
      as.data.frame() %>%
      rename(
        comp_sale_price = meta_sale_price,
        comp_sale_date = meta_sale_date,
        comp_latitude = loc_latitude,
        comp_longitude = loc_longitude,
        comp_geometry = geometry
      ) %>%
      rename_with(
        ~ paste0("comp_", .),
        .cols = starts_with("z_") | starts_with("agg_") | starts_with("char_")
      ) %>%
      select(-meta_card_num),
    by = c("comp_pin" = "meta_pin", "comp_document_num" = "meta_sale_document_num")
  ) %>%
  # Filter for only cards in the selected tri
  filter(ccao::town_get_triad(target_township_code) == triad)

# For each card, compute the number of smartfile comps that have the same PIN
# as at least one of the model comps.
# Start by pivoting the comps longer so that we can cross join them to the
# model comps for fast comparison
smartfile_comps_pivoted <- smartfile_comps %>%
  pivot_longer(
    cols = starts_with("COMP"),
    names_to = "comp_num",
    values_to = "comp_pin"
  ) %>%
  # Filter for only sales. We don't care about other comps, because they aren't
  # comparable to the model comps, which we draw from sales
  filter(
    comp_pin %in% (training_data %>% distinct(meta_pin) %>% pull(meta_pin))
  ) %>%
  mutate(
    comp_num = as.integer(str_extract(comp_num, "\\d+")),
  )


# Calculate the distance between the target and each comparable property/sale
merged_w_dist <- merged_model_comps %>%
  mutate(
    targ_to_comp_dist_ft = st_distance(
      target_geometry, comp_geometry,
      by_element = TRUE
    ),
    targ_to_comp_dist_yrblt = abs(target_z_yrblt - comp_z_yrblt),
    targ_to_comp_dist_bldg_sf = abs(target_z_bldg_sf - comp_z_bldg_sf),
    targ_to_comp_dist_land_sf = abs(target_z_land_sf - comp_z_land_sf),
    targ_to_comp_dist_beds = abs(target_z_beds - comp_z_beds),
    targ_to_comp_dist_hbath = abs(target_z_hbath - comp_z_hbath),
    targ_to_comp_dist_fbath = abs(target_z_fbath - comp_z_fbath)
  ) %>%
  select(-target_geometry, -comp_geometry) %>%
  st_drop_geometry()

# Keep flagged PINs (multi-cards, messed up prorations, etc.)
merged_w_flags <- merged_w_dist %>%
  left_join(
    preds_pin %>%
      select(meta_pin, pred_pin_initial_fmv, pred_pin_final_fmv),
    by = c("target_pin" = "meta_pin")
  ) %>%
  setDT(key = c("target_pin", "target_card"))

# Remove flagged PINs from the merged data (no multi-card, proration, etc.), as
# the comps for such properties will only be for a single card/PIN
merged_no_flags <- merged_w_dist %>%
  inner_join(
    preds_pin %>%
      filter(
        !flag_pin_is_prorated,
        !flag_pin_is_multicard,
        !flag_pin_is_multiland,
        !flag_proration_sum_not_1
      ) %>%
      select(meta_pin, pred_pin_initial_fmv, pred_pin_final_fmv),
    by = c("target_pin" = "meta_pin")
  ) %>%
  setDT(key = c("target_pin", "target_card"))
```


```{r clean_data}
# Calculate the distance between the target and each comparable property/sale
merged_w_dist <- merged_model_comps %>%
  mutate(
    targ_to_comp_dist_ft = st_distance(
      target_geometry, comp_geometry,
      by_element = TRUE
    ),
    targ_to_comp_dist_yrblt = abs(target_z_yrblt - comp_z_yrblt),
    targ_to_comp_dist_bldg_sf = abs(target_z_bldg_sf - comp_z_bldg_sf),
    targ_to_comp_dist_land_sf = abs(target_z_land_sf - comp_z_land_sf),
    targ_to_comp_dist_beds = abs(target_z_beds - comp_z_beds),
    targ_to_comp_dist_hbath = abs(target_z_hbath - comp_z_hbath),
    targ_to_comp_dist_fbath = abs(target_z_fbath - comp_z_fbath)
  ) %>%
  select(-target_geometry, -comp_geometry) %>%
  st_drop_geometry()

# Keep flagged PINs (multi-cards, messed up prorations, etc.)
merged_w_flags <- merged_w_dist %>%
  left_join(
    preds_pin %>%
      select(meta_pin, pred_pin_initial_fmv, pred_pin_final_fmv),
    by = c("target_pin" = "meta_pin")
  ) %>%
  setDT(key = c("target_pin", "target_card"))

# Remove flagged PINs from the merged data (no multi-card, proration, etc.), as
# the comps for such properties will only be for a single card/PIN
merged_no_flags <- merged_w_dist %>%
  inner_join(
    preds_pin %>%
      filter(
        !flag_pin_is_prorated,
        !flag_pin_is_multicard,
        !flag_pin_is_multiland,
        !flag_proration_sum_not_1
      ) %>%
      select(meta_pin, pred_pin_initial_fmv, pred_pin_final_fmv),
    by = c("target_pin" = "meta_pin")
  ) %>%
  setDT(key = c("target_pin", "target_card"))
```

```{r cleanup, results="hide"}
# Cleanup unused data to free up disk space
rm(
  training_data, training_data_clean,
  training_data_clean_geo, training_data_clean_no_geo, card_locs,
  comps, comps_doc_no_long, comps_long, comps_pin_long, comps_score_long,
  smartfile_comps, smartfile_comps_pivoted, smartfile_comp_matches,
  agg_char_stats,
  merged_model_comps, merged_w_dist, preds_card, preds_pin
)
gc()
```

```{r helper_funcs}
# Function to calculate aggregate comp statistics per group and number of comps
gen_agg_stats <- function(df, group_by, n) {
  by_pin <- df[, .(
    pred_pin_final_fmv = data.table::first(pred_pin_final_fmv),
    target_sale_price = data.table::first(target_sale_price),
    wt_avg_comp_sale_price = weighted.mean(
      comp_sale_price, comp_score,
      na.rm = TRUE
    )
  ), by = c("target_pin", group_by)][, .(
    corr_comp_pin_pred = cor(
      wt_avg_comp_sale_price,
      pred_pin_final_fmv,
      use = "pairwise.complete.obs"
    ),
    corr_comp_target_sale = cor(
      wt_avg_comp_sale_price,
      target_sale_price,
      use = "pairwise.complete.obs"
    )
  ), by = group_by]
  if (!is.null(group_by)) by_pin[, group_by] <- NULL

  by_g <- df[, .(
    n = .N / n,
    n_sales = sum(!is.na(target_sale_price)) / n,
    med_pin_pred_price = median(pred_pin_final_fmv, na.rm = TRUE),
    med_target_sale_price = median(target_sale_price, na.rm = TRUE),
    wt_med_comp_sale_price = matrixStats::weightedMedian(
      comp_sale_price, comp_score,
      na.rm = TRUE
    ),
    med_target_sale_date = median(target_sale_date, na.rm = TRUE),
    wt_med_comp_sale_date = as.Date(matrixStats::weightedMedian(
      comp_sale_date, comp_score,
      na.rm = TRUE
    )),
    med_comp_dist_ft = median(targ_to_comp_dist_ft, na.rm = TRUE),
    avg_comp_dist_ft = mean(targ_to_comp_dist_ft, na.rm = TRUE),
    med_comp_dist_yrblt_sd = median(targ_to_comp_dist_yrblt, na.rm = TRUE),
    avg_comp_dist_yrblt_sd = mean(targ_to_comp_dist_yrblt, na.rm = TRUE),
    med_comp_dist_bldg_sf_sd = median(targ_to_comp_dist_bldg_sf, na.rm = TRUE),
    avg_comp_dist_bldg_sf_sd = mean(targ_to_comp_dist_bldg_sf, na.rm = TRUE),
    med_comp_dist_land_sf_sd = median(targ_to_comp_dist_land_sf, na.rm = TRUE),
    avg_comp_dist_land_sf_sd = mean(targ_to_comp_dist_land_sf, na.rm = TRUE),
    med_comp_dist_beds_sd = median(targ_to_comp_dist_beds, na.rm = TRUE),
    avg_comp_dist_beds_sd = mean(targ_to_comp_dist_beds, na.rm = TRUE),
    med_comp_dist_fbath_sd = median(targ_to_comp_dist_fbath, na.rm = TRUE),
    avg_comp_dist_fbath_sd = mean(targ_to_comp_dist_fbath, na.rm = TRUE),
    med_comp_dist_hbath_sd = median(targ_to_comp_dist_hbath, na.rm = TRUE),
    avg_comp_dist_hbath_sd = mean(targ_to_comp_dist_hbath, na.rm = TRUE),
    med_comp_score = median(comp_score, na.rm = TRUE)
  ), by = group_by]

  return(cbind(by_g, by_pin))
}

# Function to format the aggregate comp statistics for display in a datatable
format_agg_stats <- function(df) {
  df %>%
    datatable(
      rownames = FALSE,
      filter = "none",
      selection = "none",
      escape = FALSE,
      colnames = c(
        "Num. Targets" = "n",
        "Num. Sales" = "n_sales",
        "Med. PIN Pred. Price" = "med_pin_pred_price",
        "Med. Target Sale Price" = "med_target_sale_price",
        "Wt. Med. Comp. Sale Price" = "wt_med_comp_sale_price",
        "Med. Target Sale Date" = "med_target_sale_date",
        "Wt. Med. Comp. Sale Date" = "wt_med_comp_sale_date",
        "Med. Comp. Dist. (ft)" = "med_comp_dist_ft",
        "Avg. Comp. Dist. (ft)" = "avg_comp_dist_ft",
        "Med. Comp. Score" = "med_comp_score",
        "Corr. Comp. PIN Pred." = "corr_comp_pin_pred",
        "Corr. Comp. Target Sale" = "corr_comp_target_sale",
        "Med. Comp. Yrblt. Dist. (S.D.)" = "med_comp_dist_yrblt_sd",
        "Avg. Comp. Yrblt. Dist. (S.D.)" = "avg_comp_dist_yrblt_sd",
        "Med. Comp. Log Bldg. S.F. Dist. (S.D.)" = "med_comp_dist_bldg_sf_sd",
        "Avg. Comp. Log Bldg. S.F. Dist. (S.D.)" = "avg_comp_dist_bldg_sf_sd",
        "Med. Comp. Log Land S.F. Dist. (S.D.)" = "med_comp_dist_land_sf_sd",
        "Avg. Comp. Log Land S.F. Dist. (S.D.)" = "avg_comp_dist_land_sf_sd",
        "Med. Comp. Beds Dist. (S.D.)" = "med_comp_dist_beds_sd",
        "Avg. Comp. Beds Dist. (S.D.)" = "avg_comp_dist_beds_sd",
        "Med. Comp. Full Bath Dist. (S.D.)" = "med_comp_dist_fbath_sd",
        "Avg. Comp. Full Bath Dist. (S.D.)" = "avg_comp_dist_fbath_sd",
        "Med. Comp. Half Bath Dist. (S.D.)" = "med_comp_dist_hbath_sd",
        "Avg. Comp. Half Bath Dist. (S.D.)" = "avg_comp_dist_hbath_sd"
      ),
      options = list(
        autoWidth = TRUE,
        paging = FALSE,
        searching = FALSE,
        info = FALSE
      )
    ) %>%
    formatRound(
      c(
        "Med. Comp. Score", "Corr. Comp. PIN Pred.",
        "Corr. Comp. Target Sale"
      ),
      digits = 2
    ) %>%
    formatRound(
      c(
        "Num. Targets", "Num. Sales",
        "Med. Comp. Dist. (ft)", "Avg. Comp. Dist. (ft)"
      ),
      digits = 0
    ) %>%
    formatRound(
      c(
        "Med. Comp. Yrblt. Dist. (S.D.)", "Avg. Comp. Yrblt. Dist. (S.D.)",
        "Med. Comp. Log Bldg. S.F. Dist. (S.D.)", "Avg. Comp. Log Bldg. S.F. Dist. (S.D.)",
        "Med. Comp. Log Land S.F. Dist. (S.D.)", "Avg. Comp. Log Land S.F. Dist. (S.D.)",
        "Med. Comp. Beds Dist. (S.D.)", "Avg. Comp. Beds Dist. (S.D.)",
        "Med. Comp. Full Bath Dist. (S.D.)", "Avg. Comp. Full Bath Dist. (S.D.)",
        "Med. Comp. Half Bath Dist. (S.D.)", "Avg. Comp. Half Bath Dist. (S.D.)"
      ),
      digits = 3
    ) %>%
    formatCurrency(
      c(
        "Med. PIN Pred. Price", "Med. Target Sale Price",
        "Wt. Med. Comp. Sale Price"
      ),
      currency = "$",
      digits = 0
    )
}

# Function to create line plots of a statistic varying by number of comps and
# a group (township, class)
plot_n_comps_by_grp <- function(df, y, grp, y_lab, grp_lab) {
  plt <- df %>%
    ggplot() +
    geom_line(
      aes(
        group = get(grp),
        x = n_comps,
        y = get(y),
        color = get(grp)
      )
    ) +
    geom_point(
      aes(
        group = get(grp),
        x = n_comps,
        y = get(y),
        color = get(grp),
        text = paste0(
          grp_lab, ": ", get(grp), "<br>",
          "Med. Sale Price: ", scales::dollar(med_target_sale_price, accuracy = 1), "<br>",
          "Med. Estimate FMV: ", scales::dollar(med_pin_pred_price, accuracy = 1), "<br>",
          "Wt. Med. Comp. Price: ", scales::dollar(wt_med_comp_sale_price, accuracy = 1), "<br>",
          "Med. Comp. Dist.: ", round(med_comp_dist_ft, 2), "<br>",
          "Med. Comp. Yrblt. Dist.: ", round(med_comp_dist_yrblt_sd, 3), "<br>",
          "Med. Comp. Log Bldg. S.F. Dist.: ", round(med_comp_dist_bldg_sf_sd, 3), "<br>",
          "Med. Comp. Log Land S.F. Dist.: ", round(med_comp_dist_land_sf_sd, 3), "<br>",
          "Med. Comp. Beds Dist.: ", round(med_comp_dist_beds_sd, 3), "<br>",
          "Med. Comp. Full Bath Dist.: ", round(med_comp_dist_fbath_sd, 3), "<br>",
          "Med. Comp. Half Bath Dist.: ", round(med_comp_dist_hbath_sd, 3), "<br>",
          "Med. Comp. Score: ", scales::percent(med_comp_score, accuracy = 1)
        )
      )
    ) +
    scale_x_continuous(
      name = "Number of Comps",
      n.breaks = total_n_comps
    ) +
    scale_y_continuous(name = y_lab) +
    labs(color = grp_lab) +
    theme_minimal()

  gplt <- ggplotly(plt, tooltip = "text")

  return(gplt)
}

# Function to help create a scatter plot comparing target/comp/predicted price
plot_ind_obs <- function(df, x, y, grp, x_lab, y_lab, grp_lab) {
  plt <- df %>%
    ggplot() +
    geom_point(
      aes(
        group = target_pin,
        x = get(x),
        y = get(y),
        color = get(grp),
        text = paste0(
          "Township: ", target_township_name, "<br>",
          "PIN: ", target_pin, "<br>",
          "Class: ", target_class, "<br>",
          "Sale Price: ", scales::dollar(target_sale_price, accuracy = 1), "<br>",
          "Estimate FMV: ", scales::dollar(pred_pin_final_fmv, accuracy = 1), "<br>",
          "Avg. Comp. Price: ", scales::dollar(wt_avg_comp_sale_price, accuracy = 1), "<br>",
          "Avg. Comp. Score: ", scales::percent(avg_comp_score, accuracy = 1)
        )
      )
    ) +
    geom_abline(slope = 1, intercept = 0) +
    scale_x_continuous(
      name = x_lab,
      labels = scales::label_dollar(
        accuracy = 1,
        scale = 1 / 1000,
        suffix = "K"
      ),
      n.breaks = 8,
      limits = c(0, 1.5e6)
    ) +
    scale_y_continuous(
      name = y_lab,
      labels = scales::label_dollar(
        accuracy = 1,
        scale = 1 / 1000,
        suffix = "K"
      ),
      n.breaks = 8,
      limits = c(0, 1.5e6)
    ) +
    labs(color = grp_lab) +
    theme_minimal()

  gplt <- ggplotly(plt, tooltip = "text")

  return(gplt)
}

# Version of plot_ind_obs for characteristics
plot_ind_char_obs <- function(
    df, x, y, grp, x_lab, y_lab, grp_lab, slope = 1, labels = waiver()) {
  plt <- df %>%
    ggplot() +
    geom_point(
      aes(
        group = target_pin,
        x = get(x),
        y = get(y),
        color = get(grp),
        text = paste0(
          "Township: ", target_township_name, "<br>",
          "PIN: ", target_pin, "<br>",
          "Class: ", target_class, "<br>",
          "Estimate FMV: ", scales::dollar(pred_pin_final_fmv, accuracy = 1), "<br>",
          "Median Comp. Dist. (ft.): ", round(med_comp_dist_ft, 2), "<br>",
          "Wt. Avg. Comp. Dist. (ft.): ", round(wt_avg_comp_dist_ft, 2), "<br>",
          "Target Yrblt.: ", target_char_yrblt, "<br>",
          "Wt. Avg. Comp. Yrblt.: ", round(wt_avg_comp_char_yrblt, 2), "<br>",
          "Target Bldg. S.F.: ", target_char_bldg_sf, "<br>",
          "Wt. Avg. Comp. Bldg. S.F.: ", round(wt_avg_comp_char_bldg_sf, 2), "<br>",
          "Target Land S.F.: ", target_char_land_sf, "<br>",
          "Wt. Avg. Comp. Land S.F.: ", round(wt_avg_comp_char_land_sf, 2), "<br>",
          "Target Beds: ", target_char_beds, "<br>",
          "Wt. Avg. Comp. Beds: ", round(wt_avg_comp_char_beds, 2), "<br>",
          "Target Full Baths: ", target_char_fbath, "<br>",
          "Wt. Avg. Comp. Full Baths: ", round(wt_avg_comp_char_fbath, 2), "<br>",
          "Target Half Baths: ", target_char_hbath, "<br>",
          "Wt. Avg. Comp. Half Baths: ", round(wt_avg_comp_char_hbath, 2), "<br>",
          "Avg. Comp. Score: ", scales::percent(avg_comp_score, accuracy = 1)
        )
      )
    ) +
    geom_abline(slope = slope, intercept = 0) +
    scale_x_continuous(
      name = x_lab,
      labels = labels
    ) +
    scale_y_continuous(name = y_lab) +
    labs(color = grp_lab) +
    theme_minimal()

  gplt <- ggplotly(plt, tooltip = "text")

  return(gplt)
}
```

## Topline Aggregate Stats

::: {.panel-tabset}

### Overall

```{r perf_overall}
#| column: screen

merged_no_flags %>%
  filter(comp_num <= keep_top_n_comps) %>%
  gen_agg_stats(NULL, keep_top_n_comps) %>%
  format_agg_stats()
```

### By Township

```{r perf_township, out.width = "100%"}
#| column: screen

merged_no_flags %>%
  filter(comp_num <= keep_top_n_comps) %>%
  gen_agg_stats("target_township_code", keep_top_n_comps) %>%
  mutate(
    Triad = ccao::town_get_triad(target_township_code, name = TRUE),
    target_township_code = ccao::town_convert(target_township_code)
  ) %>%
  rename(Township = target_township_code) %>%
  relocate(Triad, .before = Township) %>%
  arrange(Triad, Township) %>%
  format_agg_stats()
```

### By Class

```{r perf_class, out.width = "100%"}
#| column: screen

merged_no_flags %>%
  filter(comp_num <= keep_top_n_comps) %>%
  gen_agg_stats("target_class", keep_top_n_comps) %>%
  rename(Class = target_class) %>%
  format_agg_stats()
```

### By Num. Comps

```{r perf_num_comps, out.width = "100%"}
#| column: screen

map_dfr(1:total_n_comps, ~ {
  merged_no_flags %>%
    filter(comp_num <= .x) %>%
    gen_agg_stats(NULL, .x) %>%
    mutate(`Num. Comps` = .x) %>%
    select(`Num. Comps`, everything())
}) %>%
  format_agg_stats()
```

:::


```{r plot_data_prep}
# Aggregate long comps to the PIN level, keeping only properties with sales
# of the target PIN
comps_by_pin_sales_agg <- merged_no_flags[
  comp_num <= keep_top_n_comps & !is.na(target_sale_price),
][, .(
  pred_pin_final_fmv = data.table::first(pred_pin_final_fmv),
  target_sale_price = data.table::first(target_sale_price),
  avg_comp_score = mean(comp_score, na.rm = TRUE),
  wt_avg_comp_sale_price = weighted.mean(
    comp_sale_price, comp_score,
    na.rm = TRUE
  ),
  med_comp_dist_ft = targ_to_comp_dist_ft %>%
    as.vector() %>%
    median(na.rm = TRUE),
  wt_avg_comp_dist_ft = targ_to_comp_dist_ft %>%
    as.vector() %>%
    weighted.mean(comp_score, na.rm = TRUE),
  target_char_yrblt = data.table::first(target_char_yrblt),
  wt_avg_comp_char_yrblt = weighted.mean(
    comp_char_yrblt, comp_score,
    na.rm = TRUE
  ),
  target_char_bldg_sf = data.table::first(target_char_bldg_sf),
  wt_avg_comp_char_bldg_sf = weighted.mean(
    comp_char_bldg_sf, comp_score,
    na.rm = TRUE
  ),
  target_char_land_sf = data.table::first(target_char_land_sf),
  wt_avg_comp_char_land_sf = weighted.mean(
    comp_char_land_sf, comp_score,
    na.rm = TRUE
  ),
  target_char_beds = data.table::first(target_char_beds),
  wt_avg_comp_char_beds = weighted.mean(
    comp_char_beds, comp_score,
    na.rm = TRUE
  ),
  target_char_fbath = data.table::first(target_char_fbath),
  wt_avg_comp_char_fbath = weighted.mean(
    comp_char_fbath, comp_score,
    na.rm = TRUE
  ),
  target_char_hbath = data.table::first(target_char_hbath),
  wt_avg_comp_char_hbath = weighted.mean(
    comp_char_hbath, comp_score,
    na.rm = TRUE
  )
), by = c("target_pin", "target_township_code", "target_class")][
  , target_township_name := ccao::town_convert(target_township_code)
]

# Take a sample of target properties with sales to plot using plotly. Sample
# because using all properties makes the plots too large to render
comps_by_pin_sales_agg_sample <- comps_by_pin_sales_agg[sample(.N, 10000)]
```

## Target Characteristic vs Weighted Average Comp Characteristic

*The plots below use a sample of 10,000 individual target properties with sales*

::: {.panel-tabset}

### Sale Price By Township

```{r plot_targ_sale_v_avg_comp_town, out.width = "100%"}
plot_ind_obs(
  comps_by_pin_sales_agg_sample,
  "target_sale_price",
  "wt_avg_comp_sale_price",
  "target_township_name",
  "Target Sale Price",
  "Wtd. Avg. Comp Sale Price",
  "Township"
)
```

### Sale Price By Class

```{r plot_targ_sale_v_avg_comp_class, out.width = "100%"}
plot_ind_obs(
  comps_by_pin_sales_agg_sample,
  "target_sale_price",
  "wt_avg_comp_sale_price",
  "target_class",
  "Target Sale Price",
  "Wtd. Avg. Comp Sale Price",
  "Class"
)
```

### Prediction By Township

```{r plot_pred_v_avg_comp_town, out.width = "100%"}
plot_ind_obs(
  comps_by_pin_sales_agg_sample,
  "pred_pin_final_fmv",
  "wt_avg_comp_sale_price",
  "target_township_name",
  "Model Estimated FMV",
  "Wtd. Avg. Comp Sale Price",
  "Township"
)
```

### Prediction By Class

```{r plot_pred_v_avg_comp_class, out.width = "100%"}
plot_ind_obs(
  comps_by_pin_sales_agg_sample,
  "pred_pin_final_fmv",
  "wt_avg_comp_sale_price",
  "target_class",
  "Model Estimated FMV",
  "Wtd. Avg. Comp Sale Price",
  "Class"
)
```

### Median Distance By Township

```{r plot_median_dist_sf_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "pred_pin_final_fmv",
  "med_comp_dist_ft",
  "target_township_name",
  "Model Estimated FMV",
  "Median Comp Distance (ft)",
  "Township",
  slope = 0,
  labels = scales::label_dollar(accuracy = 1, scale = 1 / 1000, suffix = "K")
)
```

### Median Distance By Class

```{r plot_median_dist_sf_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "pred_pin_final_fmv",
  "med_comp_dist_ft",
  "target_class",
  "Model Estimated FMV",
  "Median Comp Distance (ft)",
  "Class",
  slope = 0,
  labels = scales::label_dollar(accuracy = 1, scale = 1 / 1000, suffix = "K")
)
```

### Average Distance By Township

```{r plot_avg_dist_sf_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "pred_pin_final_fmv",
  "wt_avg_comp_dist_ft",
  "target_township_name",
  "Model Estimated FMV",
  "Wt. Avg. Comp Distance (ft)",
  "Township",
  slope = 0,
  labels = scales::label_dollar(accuracy = 1, scale = 1 / 1000, suffix = "K")
)
```

### Average Distance By Class

```{r plot_avg_dist_sf_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "pred_pin_final_fmv",
  "wt_avg_comp_dist_ft",
  "target_class",
  "Model Estimated FMV",
  "Wt. Avg. Comp Distance (ft)",
  "Class",
  slope = 0,
  labels = scales::label_dollar(accuracy = 1, scale = 1 / 1000, suffix = "K")
)
```

### Yrblt. By Township

```{r plot_yrblt_v_avg_comp_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_yrblt",
  "wt_avg_comp_char_yrblt",
  "target_township_name",
  "Target Yrblt.",
  "Wtd. Avg. Comp Yrblt.",
  "Township"
)
```

### Yrblt. By Class

```{r plot_yrblt_v_avg_comp_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_yrblt",
  "wt_avg_comp_char_yrblt",
  "target_class",
  "Target Yrblt.",
  "Wtd. Avg. Comp Yrblt.",
  "Class"
)
```

### Bldg. S.F. By Township

```{r plot_bldg_sf_v_avg_comp_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_bldg_sf",
  "wt_avg_comp_char_bldg_sf",
  "target_township_name",
  "Target Bldg. S.F.",
  "Wtd. Avg. Comp Bldg. S.F.",
  "Township"
)
```

### Bldg. S.F. By Class

```{r plot_bldg_sf_v_avg_comp_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_bldg_sf",
  "wt_avg_comp_char_bldg_sf",
  "target_class",
  "Target Bldg. S.F.",
  "Wtd. Avg. Comp Bldg. S.F.",
  "Class"
)
```

### Land S.F. By Township

```{r plot_land_sf_v_avg_comp_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_land_sf",
  "wt_avg_comp_char_land_sf",
  "target_township_name",
  "Target Land S.F.",
  "Wtd. Avg. Comp Land S.F.",
  "Township"
)
```

### Land S.F. By Class

```{r plot_land_sf_v_avg_comp_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_land_sf",
  "wt_avg_comp_char_land_sf",
  "target_class",
  "Target Land S.F.",
  "Wtd. Avg. Comp Land S.F.",
  "Class"
)
```

### Beds By Township

```{r plot_beds_v_avg_comp_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_beds",
  "wt_avg_comp_char_beds",
  "target_township_name",
  "Target Beds",
  "Wtd. Avg. Comp Beds",
  "Township"
)
```

### Beds By Class

```{r plot_beds_v_avg_comp_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_beds",
  "wt_avg_comp_char_beds",
  "target_class",
  "Target Beds",
  "Wtd. Avg. Comp Beds",
  "Class"
)
```

### Full Baths By Township

```{r plot_fbath_v_avg_comp_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_fbath",
  "wt_avg_comp_char_fbath",
  "target_township_name",
  "Target Full Baths",
  "Wtd. Avg. Comp Full Baths",
  "Township"
)
```

### Full Baths By Class

```{r plot_fbath_v_avg_comp_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_fbath",
  "wt_avg_comp_char_fbath",
  "target_class",
  "Target Full Baths",
  "Wtd. Avg. Comp Full Baths",
  "Class"
)
```

### Half Baths By Township

```{r plot_hbath_v_avg_comp_town, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_hbath",
  "wt_avg_comp_char_hbath",
  "target_township_name",
  "Target Half Baths",
  "Wtd. Avg. Comp Half Baths",
  "Township"
)
```

### Half Baths By Class

```{r plot_hbath_v_avg_comp_class, out.width = "100%"}
plot_ind_char_obs(
  comps_by_pin_sales_agg_sample,
  "target_char_hbath",
  "wt_avg_comp_char_hbath",
  "target_class",
  "Target Half Baths",
  "Wtd. Avg. Comp Half Baths",
  "Class"
)
```

:::
